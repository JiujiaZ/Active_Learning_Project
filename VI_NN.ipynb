{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tD9Ga46BWZ8w"
   },
   "source": [
    "Aim: initial size = 10, find setting AL is superior than IID, use default lr\n",
    "<br> \n",
    "Try: (1) n = 1, mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pj8JwyyFdQvo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, distributions\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544,
     "referenced_widgets": [
      "8e8e0c29f08c41e58a5ef1c538942944",
      "17ebeed3f1f54107a5265cbebf3cd72a",
      "827da8f3618f4e33b967a74416f6d32f",
      "60a79628153b4db087849ba72a954356",
      "98796061537b4a08892a73e1df95d3f2",
      "5688c2a58f79455fb66605ec637cf0d2",
      "46cb5e25c9424d6b94e38d188816c64a",
      "9bbbb11244294ad3a4b391e69b07bb58",
      "92866e9dc5de4675a4e2654b41979159",
      "88335236f2e74acf86186ea07a8748c1",
      "9776a5019da043bda3c34304446c6468",
      "1bc2a174b92c485dbc2f3d010eed9452",
      "335849cddce44cabaac42aa144c6a36d",
      "18b8cde1c1284928a66edcc14d656276",
      "019a04bb23a54af48ce2f3b7b3992504",
      "8b34c5425c6e4c5aa754b30af6b17188",
      "9af1a4b5971246ecae0c3184b966447e",
      "2eaefb7459374adaaf303ccb62977e80",
      "bf1d10e818a54ac58d663c03fc7ec8ec",
      "0df7f791902b471f97b7d3431cccae60",
      "c993739faef6407283c097746d6ab487",
      "c86775d73992432ebc2bcd2d4ddf7dca",
      "df39be5b13ec4dbf97e6bff3b7857761",
      "f552b2a0366f47758132545a7f86d25b",
      "220f73e8acba41ae958d23613648bd73",
      "dac56640b523457286bfce618cb5b3ff",
      "2eb18081ddd943be94b052bdb0a4c21e",
      "717081bc4d2545e09010e12a0a69cc73",
      "848274ab7fca43c992b9343072041534",
      "0c4c30db3eb74663b1427165d47fc48b",
      "1e2b0b9c30d247c2b024b0f9235d52a0",
      "08b8ad52bb694d59a9d288230706e856"
     ]
    },
    "id": "WvJsuwgRdQvr",
    "outputId": "0274838c-0de3-4812-d630-c49517edee70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8e0c29f08c41e58a5ef1c538942944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92866e9dc5de4675a4e2654b41979159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af1a4b5971246ecae0c3184b966447e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220f73e8acba41ae958d23613648bd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = datasets.MNIST(\"../data\", train=True, download=True, transform=ToTensor())\n",
    "mnist_test  = datasets.MNIST(\"../data\", train=False,download=True, transform=ToTensor())\n",
    "traindataloader = DataLoader(mnist_train, shuffle=True, batch_size=60000)\n",
    "testdataloader  = DataLoader(mnist_test , shuffle=True, batch_size=10000)\n",
    "X_train, y_train = next(iter(traindataloader))\n",
    "X_test , y_test  = next(iter(testdataloader))\n",
    "\n",
    "X_train = X_train.reshape(60000, -1)\n",
    "X_test = X_test.reshape(10000, -1)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AJDDsAzIWpfk"
   },
   "outputs": [],
   "source": [
    "# sepeate train data into (1) initial, (2) pool\n",
    "initial_idx = np.array([],dtype=int)\n",
    "for i in range(10):\n",
    "    idx = np.random.choice(np.where(y_train==i)[0], size=1, replace=False)\n",
    "    initial_idx = np.concatenate((initial_idx, idx))\n",
    "\n",
    "X_initial = X_train[initial_idx]\n",
    "y_initial = y_train[initial_idx]\n",
    "\n",
    "X_pool = np.delete(X_train, initial_idx, axis=0)\n",
    "y_pool = np.delete(y_train, initial_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueGHFnNHW8lH"
   },
   "outputs": [],
   "source": [
    "# BALD Acquisition function (incomplete sampling in paper)\n",
    "def bald(model_A, model_S1, model_S2, X, n_instances, T = 100):\n",
    "  \n",
    "    random_subset = np.random.choice(range(len(X)), size=len(X), replace=False)\n",
    "    with torch.no_grad():\n",
    "        x = X[random_subset].to(device)\n",
    "        outputs = np.stack([torch.exp(model_A(x)).detach().cpu().numpy() for t in range(T)])\n",
    "\n",
    "    pc = outputs.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(outputs * np.log(outputs + 1e-10), axis=-1), axis=0) \n",
    "    acquisition = H - E_H\n",
    "    idx = (-acquisition).argsort()[:n_instances]\n",
    "    query_idx = random_subset[idx]\n",
    "\n",
    "    score_A = acquisition[query_idx]\n",
    "    \n",
    "    #---------------- score for successors:\n",
    "    with torch.no_grad():\n",
    "        output_S1 = np.stack([torch.exp(model_S1(X[query_idx].to(device))).detach().cpu().numpy() for t in range(T)])\n",
    "        output_S2 = np.stack([torch.exp(model_S2(X[query_idx].to(device))).detach().cpu().numpy() for t in range(T)])\n",
    "\n",
    "    pc = output_S1.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(output_S1 * np.log(output_S1 + 1e-10), axis=-1), axis=0) \n",
    "    score_S1 = H - E_H\n",
    "\n",
    "    pc = output_S2.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(output_S2 * np.log(output_S2 + 1e-10), axis=-1), axis=0) \n",
    "    score_S2 = H - E_H\n",
    "\n",
    "    return (query_idx, score_A, score_S1, score_S2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qqpHId4kpXS0"
   },
   "outputs": [],
   "source": [
    "# BALD Acquisition function (in use)\n",
    "def bald(model_A, model_S1, model_S2, X, n_instances, T = 100):\n",
    "    with torch.no_grad():\n",
    "        x = X.to(device)\n",
    "        outputs = np.stack([torch.exp(model_A(x, eval = True)).detach().cpu().numpy() for t in range(T)])\n",
    "\n",
    "    pc = outputs.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(outputs * np.log(outputs + 1e-10), axis=-1), axis=0) \n",
    "    acquisition = H - E_H\n",
    "    query_idx = (-acquisition).argsort()[:n_instances]\n",
    "\n",
    "    score_A = acquisition[query_idx]\n",
    "    \n",
    "    #---------------- score for successors:\n",
    "    with torch.no_grad():\n",
    "        output_S1 = np.stack([torch.exp(model_S1(X[query_idx].to(device), eval = True)).detach().cpu().numpy() for t in range(T)])\n",
    "        output_S2 = np.stack([torch.exp(model_S2(X[query_idx].to(device), eval = True)).detach().cpu().numpy() for t in range(T)])\n",
    "\n",
    "    pc = output_S1.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(output_S1 * np.log(output_S1 + 1e-10), axis=-1), axis=0) \n",
    "    score_S1 = H - E_H\n",
    "\n",
    "    pc = output_S2.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(output_S2 * np.log(output_S2 + 1e-10), axis=-1), axis=0) \n",
    "    score_S2 = H - E_H\n",
    "\n",
    "    return (query_idx, score_A, score_S1, score_S2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FT5L2GeRrKW0"
   },
   "outputs": [],
   "source": [
    "# IID acquistion:\n",
    "def iid_acq(model_A, model_S1, model_S2, X, n_instances, T = 100):\n",
    "\n",
    "    query_idx = np.random.choice(range(len(X)), size=n_instances, replace=False)\n",
    "    with torch.no_grad():\n",
    "        x = X[query_idx].to(device)\n",
    "        outputs = np.stack([torch.exp(model_A(x, eval = True)).detach().cpu().numpy() for t in range(T)])\n",
    "        output_S1 = np.stack([torch.exp(model_S1(x, eval = True)).detach().cpu().numpy() for t in range(T)])\n",
    "        output_S2 = np.stack([torch.exp(model_S2(x, eval = True)).detach().cpu().numpy() for t in range(T)])\n",
    "\n",
    "    pc = outputs.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(outputs * np.log(outputs + 1e-10), axis=-1), axis=0) \n",
    "    score_A = H - E_H\n",
    "    \n",
    "    #---------------- score for the other 2 models:\n",
    "    pc = output_S1.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(output_S1 * np.log(output_S1 + 1e-10), axis=-1), axis=0) \n",
    "    score_S1 = H - E_H\n",
    "\n",
    "    pc = output_S2.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(output_S2 * np.log(output_S2 + 1e-10), axis=-1), axis=0) \n",
    "    score_S2 = H - E_H\n",
    "\n",
    "    return (query_idx, score_A, score_S1, score_S2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rgnC6nsEamBZ"
   },
   "outputs": [],
   "source": [
    "def active_learning_procedure(X_test,\n",
    "                              y_test,\n",
    "                              X_pool,\n",
    "                              y_pool,\n",
    "                              X_initial,\n",
    "                              y_initial,\n",
    "                              n_queries=100, \n",
    "                              n_instances=1,\n",
    "                              sample_strategy = 'bald',\n",
    "                              Model_A = 1,\n",
    "                              Model_S1 = 2,\n",
    "                              Model_S2 = 3):\n",
    "\n",
    "    pool_idx = list()\n",
    "    train_ls = list()\n",
    "    x_train_sample = X_initial\n",
    "    y_train_sample = y_initial\n",
    "    train_loader = DataLoader(list(zip(x_train_sample,  y_train_sample)), \n",
    "                      shuffle=True, batch_size = 10)\n",
    "\n",
    "    #valid_idx = np.random.randint(0, len(y_pool), len(x_train_sample))\n",
    "    #x_valid = X_pool[valid_idx]\n",
    "    #y_valid = y_pool[valid_idx]\n",
    "\n",
    "    #valid_loader = DataLoader(list(zip(x_valid,  y_valid)), \n",
    "    #                  shuffle=False, batch_size = len(x_valid))\n",
    "\n",
    "    #----- Model A --------------------------\n",
    "    if (Model_A==1):\n",
    "        A = Model1(784, 10, n_batch = len(train_loader)).to(device)\n",
    "        early_epoch = 100\n",
    "    elif (Model_A ==2 ):\n",
    "        A = Model2(784, 392, 10, n_batch = len(train_loader)).to(device)\n",
    "        early_epoch = 200\n",
    "    elif (Model_A == 3):\n",
    "        A = Model3(784, [392, 196], 10, n_batch = len(train_loader)).to(device)\n",
    "        early_epoch = 500\n",
    "    else:\n",
    "        print('Invalid option for Model_A')\n",
    "        return\n",
    "    A.reset_bs()\n",
    "    optim0 = torch.optim.Adam(A.parameters(), lr=0.001)\n",
    "    ls, acc = train(A, optim0, 1000, train_loader, X_test, y_test, early_epoch, verbose = False)\n",
    "    acquisition_hist  = [acc]\n",
    "    #train_ls.append(ls)\n",
    "\n",
    "\n",
    "    #----- Model S --------------------------\n",
    "    if (Model_S1 == 1):\n",
    "        S1 = Model1(784, 10, n_batch = len(train_loader)).to(device)\n",
    "        early_epoch = 100\n",
    "    elif (Model_S1 ==2):\n",
    "        S1 = Model2(784, 392, 10, n_batch = len(train_loader)).to(device)\n",
    "        early_epoch = 200\n",
    "    else:\n",
    "        print('Invalid option for Model_S1')\n",
    "        return\n",
    "    S1.reset_bs()\n",
    "    optim1 = torch.optim.Adam(S1.parameters(), lr=0.001)\n",
    "    _, acc = train(S1, optim1, 1000, train_loader, X_test, y_test, early_epoch, verbose = False)\n",
    "    successor1_hist = [acc]\n",
    "\n",
    "    if (Model_S2 == 1):\n",
    "        S2 = Model1(784, 10, n_batch = len(train_loader)).to(device)\n",
    "        early_epoch = 100\n",
    "    elif (Model_S2 ==3):\n",
    "        S2 = Model3(784, [392, 196], 10, n_batch = len(train_loader)).to(device)\n",
    "        early_epoch = 500\n",
    "    else:\n",
    "        print('Invalid option for Model_A')\n",
    "        return\n",
    "    S2.reset_bs()  \n",
    "    optim2 = torch.optim.Adam(S2.parameters(), lr=0.001)\n",
    "    ls, acc = train(S2, optim2, 1000,  train_loader, X_test, y_test, early_epoch, verbose = False)\n",
    "    successor2_hist = [acc]\n",
    "    train_ls.append(ls)\n",
    "\n",
    "    scores = list()\n",
    "\n",
    "    for index in range(n_queries):\n",
    "        # for incomplete sampling (paper):\n",
    "        #query_idx = np.concatenate([bald(A, X_pool) for n in range(n_instances)])\n",
    "\n",
    "        # for complete set sampling:\n",
    "        if (sample_strategy  == 'bald'):\n",
    "            query_idx, score_A, score_S1, score_S2 = bald(A, S1, S2, X_pool, n_instances)\n",
    "        elif (sample_strategy == 'iid'):\n",
    "            query_idx, score_A, score_S1, score_S2 = iid_acq(A, S1, S2, X_pool, n_instances)\n",
    "        else:\n",
    "            print('Unexpected sampling strategy')\n",
    "            break\n",
    "        \n",
    "        # record scores:\n",
    "        scores.append(np.vstack((score_A, score_S1, score_S2)))\n",
    "\n",
    "        x_train_sample = torch.vstack((x_train_sample, X_pool[query_idx]))\n",
    "        y_train_sample = torch.cat((y_train_sample,y_pool[query_idx]))\n",
    "        train_loader = DataLoader(list(zip(x_train_sample,  y_train_sample)), \n",
    "                      shuffle=True, batch_size = 10)\n",
    "\n",
    "        #valid_idx = np.random.randint(0, len(y_pool), len(x_train_sample))\n",
    "        #x_valid = X_pool[valid_idx]\n",
    "        #y_valid = y_pool[valid_idx]\n",
    "        #valid_loader = DataLoader(list(zip(x_valid,  y_valid)), \n",
    "        #              shuffle=False, batch_size = len(x_valid))\n",
    "\n",
    "        # model A:\n",
    "        if (Model_A==1):\n",
    "            A = Model1(784, 10, n_batch = len(train_loader)).to(device)\n",
    "            early_epoch = 100\n",
    "        elif (Model_A ==2 ):\n",
    "            A = Model2(784, 392, 10, n_batch = len(train_loader)).to(device)\n",
    "            early_epoch = 200\n",
    "        elif (Model_A == 3):\n",
    "            A = Model3(784, [392, 196], 10, n_batch = len(train_loader)).to(device)\n",
    "            early_epoch = 500\n",
    "        else:\n",
    "            print('Invalid option for Model_A')\n",
    "            return\n",
    "        A.reset_bs()\n",
    "        optim0 = torch.optim.Adam(A.parameters(), lr=0.001)\n",
    "        ls, acc = train(A, optim0, 1000, train_loader, X_test, y_test, early_epoch, verbose = False)\n",
    "        acquisition_hist.append(acc)\n",
    "        #train_ls.append(ls)\n",
    "\n",
    "        # model S:\n",
    "        if (Model_S1 == 1):\n",
    "            S1 = Model1(784, 10, n_batch = len(train_loader)).to(device)\n",
    "            early_epoch = 100\n",
    "        elif (Model_S1 ==2):\n",
    "            S1 = Model2(784, 392, 10, n_batch = len(train_loader)).to(device)\n",
    "            early_epoch = 200\n",
    "        else:\n",
    "            print('Invalid option for Model_S1')\n",
    "            return\n",
    "        S1.reset_bs()\n",
    "        optim1 = torch.optim.Adam(S1.parameters(), lr=0.001)\n",
    "        _, acc = train(S1, optim1, 1000,  train_loader, X_test, y_test, early_epoch, verbose = False)\n",
    "        successor1_hist.append(acc)\n",
    "\n",
    "        if (Model_S2 == 1):\n",
    "            S2 = Model1(784, 10, n_batch = len(train_loader)).to(device)\n",
    "            early_epoch = 100\n",
    "        elif (Model_S2 ==3):\n",
    "            S2 = Model3(784, [392, 196], 10, n_batch = len(train_loader)).to(device)\n",
    "            early_epoch = 500\n",
    "        else:\n",
    "            print('Invalid option for Model_A')\n",
    "            return  \n",
    "        S2.reset_bs()\n",
    "        optim2 = torch.optim.Adam(S2.parameters(), lr=0.001)\n",
    "        ls, acc = train(S2, optim2, 1000, train_loader, X_test, y_test, early_epoch, verbose = False)\n",
    "        successor2_hist.append(acc)\n",
    "        train_ls.append(ls)\n",
    "\n",
    "        \n",
    "        # delete queried data from pool:\n",
    "        X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "        y_pool = np.delete(y_pool, query_idx, axis=0)\n",
    "\n",
    "        print('Query {n}: {acc:0.4f}(Model A)    |     {acc_s1:0.4f}(Model S1) - {acc_s2:0.4f}(Model S2) '.format(n=index + 1, \n",
    "                                                                                                                  acc=acquisition_hist[-1], \n",
    "                                                                                                                  acc_s1 = successor1_hist[-1], \n",
    "                                                                                                                  acc_s2 = successor2_hist[-1]))     \n",
    "        pool_idx.append(query_idx)\n",
    "    return(acquisition_hist, successor1_hist, successor2_hist, scores, pool_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "P01kRIEGdQvs"
   },
   "outputs": [],
   "source": [
    "class LinearVariational(nn.Module):\n",
    "    def __init__(self, in_features, out_features, loss_accumulator, batch_num, n_batch, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.include_bias = bias        \n",
    "        self.loss_accumulator = loss_accumulator\n",
    "        self.n_batch = n_batch\n",
    "        self.batch_num = batch_num\n",
    "        \n",
    "        if getattr(loss_accumulator, 'accumulated_kl_div', None) is None:\n",
    "            loss_accumulator.accumulated_kl_div = 0\n",
    "        if getattr(batch_num, 'accumulated_bs', None) is None:\n",
    "            batch_num.accumulated_bs = 0\n",
    "\n",
    "        # mean:\n",
    "        self.w_mu = nn.Parameter(\n",
    "            torch.FloatTensor(in_features, out_features).normal_(mean=0, std=0.001)\n",
    "        )\n",
    "         \n",
    "        # variance log(1 + exp(p))â—¦ eps:\n",
    "        self.w_p = nn.Parameter(\n",
    "            torch.FloatTensor(in_features, out_features).normal_(mean=-2.5, std=0.001)\n",
    "        )\n",
    "        if self.include_bias:\n",
    "            self.b_mu = nn.Parameter(\n",
    "                torch.zeros(out_features)\n",
    "            )\n",
    "            self.b_p = nn.Parameter(\n",
    "                torch.zeros(out_features)\n",
    "            )\n",
    "        \n",
    "    def reparameterize(self, mu, p):\n",
    "        sigma = torch.log(1 + torch.exp(p)) \n",
    "        eps = torch.randn_like(sigma)\n",
    "        return mu + (eps * sigma)\n",
    "    \n",
    "    def kl_divergence(self, z, mu_theta, p_theta, batch_num, prior_sd=1):\n",
    "        log_prior = distributions.Normal(0, prior_sd).log_prob(z) \n",
    "        log_p_q = distributions.Normal(mu_theta, torch.log(1 + torch.exp(p_theta))).log_prob(z) \n",
    "        weights =  np.power(2,self.n_batch - batch_num) /  (np.power(2,self.n_batch)-1) \n",
    "\n",
    "        #print('batch_num {}: weights {}'.format(batch_num, weights))\n",
    "        return (log_p_q - log_prior).mean() * weights\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.reparameterize(self.w_mu, self.w_p)\n",
    "        \n",
    "        if self.include_bias:\n",
    "            b = self.reparameterize(self.b_mu, self.b_p)\n",
    "        else:\n",
    "            b = 0\n",
    "            \n",
    "        z = x @ w + b\n",
    "        \n",
    "        if (self.batch_num.clip == False):\n",
    "            self.batch_num.accumulated_bs += 1\n",
    "        self.loss_accumulator.accumulated_kl_div += self.kl_divergence(w, \n",
    "                                                             self.w_mu,\n",
    "                                                             self.w_p,\n",
    "                                                             self.batch_num.accumulated_bs\n",
    "                                                             )\n",
    "        if self.include_bias:\n",
    "            self.loss_accumulator.accumulated_kl_div += self.kl_divergence(b, \n",
    "                                                                 self.b_mu, \n",
    "                                                                 self.b_p,\n",
    "                                                                 self.batch_num.accumulated_bs\n",
    "                                                                 )\n",
    "        return z\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class KL:\n",
    "    accumulated_kl_div = 0\n",
    "class BS:\n",
    "    accumulated_bs = 0\n",
    "    clip = False\n",
    "\n",
    "def det_loss(y, y_pred, model):\n",
    "    reconstruction_error = F.nll_loss(y_pred, y,reduction=\"mean\")\n",
    "    kl = model.accumulated_kl_div\n",
    "    #model.reset_kl_div() # reset fo each batch\n",
    "    #model.reset_bs()\n",
    "    #print('rec: {} | kl: {}'.format(reconstruction_error, kl))\n",
    "    return reconstruction_error + kl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qf0y3IYxtkIk"
   },
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self, in_size, out_size, n_batch):\n",
    "        super().__init__()\n",
    "        self.kl_loss = KL\n",
    "        self.bs_num = BS\n",
    "\n",
    "        self.var = LinearVariational(in_size, out_size, self.kl_loss, self.bs_num, n_batch)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.log_softmax = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            LinearVariational(in_size, out_size, self.kl_loss, self.bs_num, n_batch),\n",
    "            nn.LogSoftmax(dim = 1)\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def accumulated_kl_div(self):\n",
    "        return self.kl_loss.accumulated_kl_div\n",
    "    \n",
    "    def reset_kl_div(self):\n",
    "        self.kl_loss.accumulated_kl_div = 0\n",
    "\n",
    "    def accumulated_bs(self):\n",
    "        return self.bs_num.accumulated_bs\n",
    "    \n",
    "    def reset_bs(self):\n",
    "        self.bs_num.accumulated_bs = 0\n",
    "    \n",
    "    def clip_bs(self, clip = True):\n",
    "        self.bs_num.clip = clip\n",
    "    \n",
    "    def set_bs(self, val):\n",
    "        self.bs_num.accumulated_bs = val\n",
    "            \n",
    "    def forward(self, x, eval = False):\n",
    "        if eval:\n",
    "            Model1.set_bs(self, val = 1)\n",
    "            Model1.clip_bs(self, clip = True)\n",
    "        else:\n",
    "            Model1.clip_bs(self, clip = False)\n",
    "        out = self.var(x)\n",
    "        out = self.log_softmax(out)\n",
    "        return out\n",
    "\n",
    "class Model2(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size, n_batch):\n",
    "        super().__init__()\n",
    "        self.kl_loss = KL\n",
    "        self.bs_num = BS\n",
    "        \n",
    "        self.var1 = LinearVariational(in_size, hidden_size, self.kl_loss, self.bs_num, n_batch)\n",
    "        self.lin1 = nn.Linear(in_size, hidden_size)\n",
    "        self.var2 = LinearVariational(hidden_size, out_size, self.kl_loss, self.bs_num, n_batch)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.log_softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def accumulated_kl_div(self):\n",
    "        return self.kl_loss.accumulated_kl_div\n",
    "    \n",
    "    def reset_kl_div(self):\n",
    "        self.kl_loss.accumulated_kl_div = 0\n",
    "\n",
    "    def accumulated_bs(self):\n",
    "        return self.bs_num.accumulated_bs\n",
    "    \n",
    "    def reset_bs(self):\n",
    "        self.bs_num.accumulated_bs = 0\n",
    "\n",
    "    def clip_bs(self, clip = True):\n",
    "        self.bs_num.clip = clip\n",
    "    \n",
    "    def set_bs(self, val):\n",
    "        self.bs_num.accumulated_bs = val\n",
    "            \n",
    "    def forward(self, x, eval = False):\n",
    "        if eval:\n",
    "            Model2.set_bs(self, val = 1)\n",
    "            Model2.clip_bs(self, clip = True)\n",
    "        else:\n",
    "            Model2.clip_bs(self, clip = False)\n",
    "        #out = self.var1(x)   \n",
    "        out = self.lin1(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        Model2.clip_bs(self)\n",
    "\n",
    "        out = self.var2(out)\n",
    "        out = self.log_softmax(out)\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "class Model3(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size, n_batch):\n",
    "        super().__init__()\n",
    "        self.kl_loss = KL\n",
    "        self.bs_num = BS\n",
    "\n",
    "        self.var1 = LinearVariational(in_size, hidden_size[0], self.kl_loss, self.bs_num, n_batch)\n",
    "        self.var2 = LinearVariational(hidden_size[0], hidden_size[1], self.kl_loss, self.bs_num, n_batch)\n",
    "        self.var3 = LinearVariational(hidden_size[1], out_size, self.kl_loss, self.bs_num, n_batch)\n",
    "\n",
    "        self.lin1 = nn.Linear(in_size, hidden_size[0])\n",
    "        self.lin2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.log_softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def accumulated_kl_div(self):\n",
    "        return self.kl_loss.accumulated_kl_div\n",
    "    \n",
    "    def reset_kl_div(self):\n",
    "        self.kl_loss.accumulated_kl_div = 0\n",
    "\n",
    "    def accumulated_bs(self):\n",
    "        return self.bs_num.accumulated_bs\n",
    "    \n",
    "    def reset_bs(self):\n",
    "        self.bs_num.accumulated_bs = 0\n",
    "\n",
    "    def clip_bs(self, clip = True):\n",
    "        self.bs_num.clip = clip\n",
    "\n",
    "    def set_bs(self, val):\n",
    "        self.bs_num.accumulated_bs = val\n",
    "            \n",
    "    def forward(self, x, eval = False):\n",
    "        if eval:\n",
    "            Model3.set_bs(self, val = 1)\n",
    "            Model3.clip_bs(self, clip = True)\n",
    "        else:\n",
    "            Model3.clip_bs(self, clip = False)\n",
    "        #out = self.var1(x)\n",
    "        out = self.lin1(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        Model3.clip_bs(self)\n",
    "        #out = self.var2(out)\n",
    "        out = self.lin2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.var3(out)\n",
    "        out = self.log_softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "W_FbZCJ0Bd-E"
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(model, optimizer, num_epoch,\n",
    "          train_loader, \n",
    "          X_test, y_test, early_epoch,\n",
    "          verbose = False):\n",
    "    train_ls = list()\n",
    "    #valid_ls = list()\n",
    "    test_acc = 0\n",
    "    train_kl = list()\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        ls = 0\n",
    "        kl = 0\n",
    "        num_correct = 0\n",
    "        data_num = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch_num, (x, y) in enumerate(train_loader):\n",
    "            #print('in train : batch_num{}'.format(batch_num))\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # forward:\n",
    "            y_pred = model(x, eval = False)\n",
    "            loss = det_loss(y, y_pred, model)\n",
    "            kl += model.accumulated_kl_div\n",
    "            model.reset_kl_div()\n",
    "            ls += loss.item()\n",
    "\n",
    "            # backward:\n",
    "            optimizer.zero_grad() # remove grad from forward prop\n",
    "            loss.backward()\n",
    "\n",
    "            # update gradient:\n",
    "            optimizer.step()\n",
    "\n",
    "            # accuracy:\n",
    "            #_, pred = torch.max(y_pred,1)\n",
    "            #num_correct += (pred == y).sum().item()\n",
    "\n",
    "            data_num += len(y)\n",
    "        model.reset_bs()\n",
    "\n",
    "        ls = ls/data_num\n",
    "        #print('valid:')\n",
    "        #val_ls = eval_ls(model, valid_loader)\n",
    "        #weights = np.power(2, len(train_loader)-1) / (np.power(2, len(train_loader)) - 1 )\n",
    "        #weights = 1\n",
    "\n",
    "        #val_ls = val_ls/weights\n",
    "        #model.reset_bs()\n",
    "        if verbose:\n",
    "            print(epoch+1)\n",
    "            print(f'\\tLoss: {ls:.4f}(train)\\t')\n",
    "        train_ls.append(ls)\n",
    "        #valid_ls.append(val_ls)\n",
    "        train_kl.append(kl/data_num)\n",
    "\n",
    "        # access early stopping:\n",
    "        #trigger = (np.array(train_ls[epoch-50:]) < np.array(valid_ls[epoch-50:])).sum()/500\n",
    "        #if (trigger > 0.5):\n",
    "        #    if verbose:\n",
    "        #        print('Epoch {} : Early Stopping - past 50 epochs half val_ls > train_ls'.format(epoch))\n",
    "        #    test_acc = eval_acc(model, X_test, y_test)\n",
    "        #    break\n",
    "\n",
    "        if ((epoch > early_epoch) & (epoch % 10 == 0)):\n",
    "            mean_1 = np.mean(train_ls[epoch-60:epoch-10])\n",
    "            mean_2 = np.mean(train_ls[epoch-50:])\n",
    "            if (mean_1 - mean_2 < 1e-3):\n",
    "                print(epoch)\n",
    "                test_acc = eval_acc(model, X_test, y_test)\n",
    "                break\n",
    "\n",
    "        if (epoch == num_epoch-1):\n",
    "            print(epoch)\n",
    "            test_acc = eval_acc(model, X_test, y_test)\n",
    "        \n",
    "\n",
    "    return(train_ls, test_acc)\n",
    "\n",
    "\n",
    "def eval_ls(model, loader):\n",
    "    ls = 0\n",
    "    data_num = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = model(x, eval = True)\n",
    "            loss = det_loss(y, y_pred, model)\n",
    "            ls += loss.item()\n",
    "\n",
    "            data_num += len(y)\n",
    "        model.reset_bs()\n",
    "    model.train()\n",
    "    return ls/data_num\n",
    "\n",
    "def eval_acc(model, test_x, test_y):\n",
    "\n",
    "    y_sample = np.stack([torch.exp(model(test_x.to(device), eval = True)).detach().cpu().numpy() for t in range(100)])\n",
    "\n",
    "    y_pred = y_sample.mean(axis = 0).argmax(axis = 1)\n",
    "\n",
    "    #y_sample = model(test_x.to(device)).detach().cpu().numpy()\n",
    "    #y_pred = y_sample.argmax(axis = 1)\n",
    "    acc = np.equal(y_pred, test_y).sum().item()/len(test_y)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "r4LGPvKryZ1k",
    "outputId": "5d22a8b1-f08e-439a-95b5-1e72323d27f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "250\n",
      "520\n",
      "200\n",
      "400\n",
      "840\n",
      "Query 1: 0.4651(Model A)    |     0.4379(Model S1) - 0.4485(Model S2) \n",
      "260\n",
      "300\n",
      "820\n",
      "Query 2: 0.4468(Model A)    |     0.4634(Model S1) - 0.4374(Model S2) \n",
      "230\n",
      "260\n",
      "680\n",
      "Query 3: 0.4503(Model A)    |     0.4713(Model S1) - 0.3918(Model S2) \n",
      "250\n",
      "240\n",
      "900\n",
      "Query 4: 0.4556(Model A)    |     0.4592(Model S1) - 0.4230(Model S2) \n",
      "210\n",
      "390\n",
      "790\n",
      "Query 5: 0.4501(Model A)    |     0.4625(Model S1) - 0.4335(Model S2) \n",
      "180\n",
      "320\n",
      "710\n",
      "Query 6: 0.4760(Model A)    |     0.5016(Model S1) - 0.4710(Model S2) \n",
      "210\n",
      "230\n",
      "530\n",
      "Query 7: 0.4896(Model A)    |     0.4974(Model S1) - 0.4992(Model S2) \n",
      "190\n",
      "380\n",
      "680\n",
      "Query 8: 0.4962(Model A)    |     0.5058(Model S1) - 0.3924(Model S2) \n",
      "210\n",
      "740\n",
      "690\n",
      "Query 9: 0.4972(Model A)    |     0.5107(Model S1) - 0.4692(Model S2) \n",
      "190\n",
      "220\n",
      "630\n",
      "Query 10: 0.4715(Model A)    |     0.4908(Model S1) - 0.5089(Model S2) \n",
      "260\n",
      "910\n",
      "999\n",
      "Query 11: 0.4822(Model A)    |     0.4635(Model S1) - 0.4534(Model S2) \n",
      "230\n",
      "920\n",
      "730\n",
      "Query 12: 0.4938(Model A)    |     0.4978(Model S1) - 0.4731(Model S2) \n",
      "230\n",
      "260\n",
      "790\n",
      "Query 13: 0.4975(Model A)    |     0.4879(Model S1) - 0.4904(Model S2) \n",
      "230\n",
      "999\n",
      "670\n",
      "Query 14: 0.5277(Model A)    |     0.5506(Model S1) - 0.4940(Model S2) \n",
      "220\n",
      "999\n",
      "620\n",
      "Query 15: 0.5384(Model A)    |     0.5374(Model S1) - 0.5157(Model S2) \n",
      "230\n",
      "999\n",
      "890\n",
      "Query 16: 0.5345(Model A)    |     0.5321(Model S1) - 0.5332(Model S2) \n",
      "210\n",
      "860\n",
      "940\n",
      "Query 17: 0.5144(Model A)    |     0.4898(Model S1) - 0.4937(Model S2) \n",
      "220\n",
      "810\n",
      "720\n",
      "Query 18: 0.5189(Model A)    |     0.4451(Model S1) - 0.5050(Model S2) \n",
      "200\n",
      "290\n",
      "620\n",
      "Query 19: 0.4705(Model A)    |     0.4953(Model S1) - 0.4645(Model S2) \n",
      "200\n",
      "810\n",
      "720\n",
      "Query 20: 0.5003(Model A)    |     0.4223(Model S1) - 0.4926(Model S2) \n",
      "210\n",
      "960\n",
      "700\n",
      "Query 21: 0.5090(Model A)    |     0.4730(Model S1) - 0.4359(Model S2) \n",
      "220\n",
      "720\n",
      "520\n",
      "Query 22: 0.5146(Model A)    |     0.4996(Model S1) - 0.4438(Model S2) \n",
      "210\n",
      "720\n",
      "710\n",
      "Query 23: 0.5021(Model A)    |     0.5050(Model S1) - 0.4873(Model S2) \n",
      "190\n",
      "870\n",
      "670\n",
      "Query 24: 0.5114(Model A)    |     0.5473(Model S1) - 0.4615(Model S2) \n",
      "200\n",
      "820\n",
      "510\n",
      "Query 25: 0.5354(Model A)    |     0.4617(Model S1) - 0.4425(Model S2) \n",
      "190\n",
      "670\n",
      "700\n",
      "Query 26: 0.5191(Model A)    |     0.5102(Model S1) - 0.5054(Model S2) \n",
      "260\n",
      "770\n",
      "540\n",
      "Query 27: 0.5199(Model A)    |     0.5198(Model S1) - 0.4646(Model S2) \n",
      "200\n",
      "670\n",
      "630\n",
      "Query 28: 0.5367(Model A)    |     0.4366(Model S1) - 0.4371(Model S2) \n",
      "200\n",
      "750\n",
      "650\n",
      "Query 29: 0.5282(Model A)    |     0.5639(Model S1) - 0.4696(Model S2) \n",
      "200\n",
      "690\n",
      "530\n",
      "Query 30: 0.5528(Model A)    |     0.5003(Model S1) - 0.4935(Model S2) \n",
      "250\n",
      "760\n",
      "560\n",
      "Query 31: 0.5716(Model A)    |     0.4892(Model S1) - 0.4937(Model S2) \n",
      "210\n",
      "690\n",
      "620\n",
      "Query 32: 0.5645(Model A)    |     0.5161(Model S1) - 0.4318(Model S2) \n",
      "200\n",
      "580\n",
      "610\n",
      "Query 33: 0.5664(Model A)    |     0.4726(Model S1) - 0.4806(Model S2) \n",
      "190\n",
      "690\n",
      "610\n",
      "Query 34: 0.5700(Model A)    |     0.5305(Model S1) - 0.5144(Model S2) \n",
      "190\n",
      "610\n",
      "740\n",
      "Query 35: 0.5523(Model A)    |     0.5281(Model S1) - 0.5524(Model S2) \n",
      "210\n",
      "540\n",
      "670\n",
      "Query 36: 0.5647(Model A)    |     0.5263(Model S1) - 0.5219(Model S2) \n",
      "210\n",
      "660\n",
      "540\n",
      "Query 37: 0.5621(Model A)    |     0.5442(Model S1) - 0.5171(Model S2) \n",
      "200\n",
      "730\n",
      "630\n",
      "Query 38: 0.5820(Model A)    |     0.5439(Model S1) - 0.5261(Model S2) \n",
      "210\n",
      "780\n",
      "700\n",
      "Query 39: 0.5686(Model A)    |     0.5146(Model S1) - 0.5116(Model S2) \n",
      "200\n",
      "670\n",
      "600\n",
      "Query 40: 0.5689(Model A)    |     0.5467(Model S1) - 0.5175(Model S2) \n",
      "210\n",
      "720\n",
      "620\n",
      "Query 41: 0.5555(Model A)    |     0.5390(Model S1) - 0.5428(Model S2) \n",
      "220\n",
      "580\n",
      "550\n",
      "Query 42: 0.5672(Model A)    |     0.4812(Model S1) - 0.5131(Model S2) \n",
      "230\n",
      "750\n",
      "650\n",
      "Query 43: 0.5547(Model A)    |     0.5389(Model S1) - 0.5256(Model S2) \n",
      "210\n",
      "430\n",
      "540\n",
      "Query 44: 0.5786(Model A)    |     0.5622(Model S1) - 0.5277(Model S2) \n",
      "220\n",
      "630\n",
      "630\n",
      "Query 45: 0.5657(Model A)    |     0.5563(Model S1) - 0.5415(Model S2) \n",
      "220\n",
      "670\n",
      "730\n",
      "Query 46: 0.5976(Model A)    |     0.5469(Model S1) - 0.5321(Model S2) \n",
      "220\n",
      "630\n",
      "510\n",
      "Query 47: 0.5914(Model A)    |     0.5629(Model S1) - 0.5337(Model S2) \n",
      "210\n",
      "700\n",
      "590\n",
      "Query 48: 0.5906(Model A)    |     0.5547(Model S1) - 0.4821(Model S2) \n",
      "230\n",
      "560\n",
      "600\n",
      "Query 49: 0.5953(Model A)    |     0.5550(Model S1) - 0.5337(Model S2) \n",
      "210\n",
      "560\n",
      "610\n",
      "Query 50: 0.5833(Model A)    |     0.5644(Model S1) - 0.5474(Model S2) \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_80e568c1-dbec-486c-856e-e8d678f6c98b\", \"res_bald_A1.npy\", 2336)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A1 BALD\n",
    "acquisition_hist, successor1_hist, successor2_hist, scores, pool_idx = active_learning_procedure(\n",
    "                                                                                X_test,\n",
    "                                                                                y_test,\n",
    "                                                                                X_pool,\n",
    "                                                                                y_pool,\n",
    "                                                                                X_initial,\n",
    "                                                                                y_initial,\n",
    "                                                                                n_queries = 20,\n",
    "                                                                                n_instances = 1,\n",
    "                                                                                Model_A = 1, Model_S1 = 2, Model_S2 = 3)\n",
    "with open('res_bald_A1.npy', 'wb') as f:\n",
    "    np.save(f, acquisition_hist)\n",
    "    np.save(f, successor1_hist)\n",
    "    np.save(f, successor2_hist)\n",
    "    np.save(f, scores)\n",
    "\n",
    "from google.colab import files\n",
    "files.download('res_bald_A1.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iqc95fxHsdap",
    "outputId": "d8de669f-6fc4-4ae8-ef55-b5526a424c2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "210\n",
      "520\n",
      "150\n",
      "260\n",
      "870\n",
      "Query 1: 0.4144(Model A)    |     0.4353(Model S1) - 0.3634(Model S2) \n",
      "240\n",
      "250\n",
      "999\n",
      "Query 2: 0.4103(Model A)    |     0.4373(Model S1) - 0.3455(Model S2) \n",
      "290\n",
      "390\n",
      "700\n",
      "Query 3: 0.4387(Model A)    |     0.4672(Model S1) - 0.4094(Model S2) \n",
      "280\n",
      "999\n",
      "920\n",
      "Query 4: 0.4237(Model A)    |     0.4519(Model S1) - 0.3615(Model S2) \n",
      "280\n",
      "430\n",
      "760\n",
      "Query 5: 0.4341(Model A)    |     0.4238(Model S1) - 0.3916(Model S2) \n",
      "230\n",
      "360\n",
      "750\n",
      "Query 6: 0.4175(Model A)    |     0.4500(Model S1) - 0.3823(Model S2) \n",
      "250\n",
      "210\n",
      "700\n",
      "Query 7: 0.4383(Model A)    |     0.4400(Model S1) - 0.3829(Model S2) \n",
      "230\n",
      "240\n",
      "530\n",
      "Query 8: 0.4441(Model A)    |     0.4606(Model S1) - 0.4021(Model S2) \n",
      "250\n",
      "220\n",
      "710\n",
      "Query 9: 0.4528(Model A)    |     0.4665(Model S1) - 0.4147(Model S2) \n",
      "220\n",
      "220\n",
      "650\n",
      "Query 10: 0.4682(Model A)    |     0.4734(Model S1) - 0.4485(Model S2) \n",
      "240\n",
      "950\n",
      "640\n",
      "Query 11: 0.4974(Model A)    |     0.4839(Model S1) - 0.4908(Model S2) \n",
      "230\n",
      "340\n",
      "670\n",
      "Query 12: 0.5005(Model A)    |     0.4997(Model S1) - 0.5025(Model S2) \n",
      "230\n",
      "999\n",
      "590\n",
      "Query 13: 0.4932(Model A)    |     0.4949(Model S1) - 0.4308(Model S2) \n",
      "210\n",
      "780\n",
      "640\n",
      "Query 14: 0.5235(Model A)    |     0.4851(Model S1) - 0.4618(Model S2) \n",
      "210\n",
      "840\n",
      "700\n",
      "Query 15: 0.5232(Model A)    |     0.4794(Model S1) - 0.5059(Model S2) \n",
      "250\n",
      "730\n",
      "850\n",
      "Query 16: 0.5321(Model A)    |     0.5252(Model S1) - 0.4954(Model S2) \n",
      "240\n",
      "740\n",
      "750\n",
      "Query 17: 0.5307(Model A)    |     0.4793(Model S1) - 0.5082(Model S2) \n",
      "200\n",
      "640\n",
      "620\n",
      "Query 18: 0.5539(Model A)    |     0.5281(Model S1) - 0.5274(Model S2) \n",
      "220\n",
      "710\n",
      "800\n",
      "Query 19: 0.5504(Model A)    |     0.5331(Model S1) - 0.5531(Model S2) \n",
      "220\n",
      "720\n",
      "730\n",
      "Query 20: 0.5458(Model A)    |     0.5283(Model S1) - 0.4570(Model S2) \n"
     ]
    }
   ],
   "source": [
    "#iid\n",
    "acquisition_hist, successor1_hist, successor2_hist, scores, pool_idx = active_learning_procedure(\n",
    "                                                                                X_test,\n",
    "                                                                                y_test,\n",
    "                                                                                X_pool,\n",
    "                                                                                y_pool,\n",
    "                                                                                X_initial,\n",
    "                                                                                y_initial,\n",
    "                                                                                n_queries = 20,\n",
    "                                                                                n_instances = 1,\n",
    "                                                                                sample_strategy = 'iid',\n",
    "                                                                                Model_A = 1, Model_S1 = 2, Model_S2 = 3)\n",
    "with open('res_iid_A1.npy', 'wb') as f:\n",
    "    np.save(f, acquisition_hist)\n",
    "    np.save(f, successor1_hist)\n",
    "    np.save(f, successor2_hist)\n",
    "    np.save(f, scores)\n",
    "\n",
    "from google.colab import files\n",
    "files.download('res_iid_A1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4rRNshoX8I1S",
    "outputId": "f271e9e6-55c7-40bd-b25f-51bdca3a3984"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "150\n",
      "510\n",
      "260\n",
      "230\n",
      "640\n",
      "Query 1: 0.4283(Model A)    |     0.4177(Model S1) - 0.4499(Model S2) \n",
      "280\n",
      "240\n",
      "930\n",
      "Query 2: 0.4400(Model A)    |     0.4267(Model S1) - 0.3692(Model S2) \n",
      "999\n",
      "220\n",
      "660\n",
      "Query 3: 0.4087(Model A)    |     0.4193(Model S1) - 0.3705(Model S2) \n",
      "310\n",
      "200\n",
      "660\n",
      "Query 4: 0.4605(Model A)    |     0.4360(Model S1) - 0.4088(Model S2) \n",
      "360\n",
      "250\n",
      "570\n",
      "Query 5: 0.4812(Model A)    |     0.4550(Model S1) - 0.4648(Model S2) \n",
      "250\n",
      "220\n",
      "730\n",
      "Query 6: 0.5004(Model A)    |     0.4895(Model S1) - 0.4315(Model S2) \n",
      "220\n",
      "250\n",
      "610\n",
      "Query 7: 0.4956(Model A)    |     0.4982(Model S1) - 0.4995(Model S2) \n",
      "330\n",
      "240\n",
      "520\n",
      "Query 8: 0.5172(Model A)    |     0.5185(Model S1) - 0.4346(Model S2) \n",
      "220\n",
      "190\n",
      "960\n",
      "Query 9: 0.5426(Model A)    |     0.5306(Model S1) - 0.4973(Model S2) \n",
      "250\n",
      "180\n",
      "570\n",
      "Query 10: 0.5426(Model A)    |     0.5356(Model S1) - 0.4946(Model S2) \n",
      "840\n",
      "260\n",
      "630\n",
      "Query 11: 0.4746(Model A)    |     0.5461(Model S1) - 0.4551(Model S2) \n",
      "999\n",
      "220\n",
      "800\n",
      "Query 12: 0.4776(Model A)    |     0.5426(Model S1) - 0.5308(Model S2) \n",
      "860\n",
      "210\n",
      "600\n",
      "Query 13: 0.5403(Model A)    |     0.5487(Model S1) - 0.5104(Model S2) \n",
      "890\n",
      "190\n",
      "760\n",
      "Query 14: 0.4941(Model A)    |     0.5397(Model S1) - 0.4850(Model S2) \n",
      "970\n",
      "230\n",
      "930\n",
      "Query 15: 0.5224(Model A)    |     0.5411(Model S1) - 0.5148(Model S2) \n",
      "700\n",
      "200\n",
      "880\n",
      "Query 16: 0.4928(Model A)    |     0.5590(Model S1) - 0.5169(Model S2) \n",
      "850\n",
      "170\n",
      "660\n",
      "Query 17: 0.5384(Model A)    |     0.5715(Model S1) - 0.4546(Model S2) \n",
      "880\n",
      "220\n",
      "770\n",
      "Query 18: 0.5273(Model A)    |     0.5558(Model S1) - 0.5243(Model S2) \n",
      "860\n",
      "210\n",
      "610\n",
      "Query 19: 0.5320(Model A)    |     0.5665(Model S1) - 0.4768(Model S2) \n",
      "840\n",
      "230\n",
      "650\n",
      "Query 20: 0.5265(Model A)    |     0.5554(Model S1) - 0.5204(Model S2) \n",
      "850\n",
      "170\n",
      "610\n",
      "Query 21: 0.5138(Model A)    |     0.5347(Model S1) - 0.5212(Model S2) \n",
      "900\n",
      "220\n",
      "600\n",
      "Query 22: 0.5172(Model A)    |     0.5492(Model S1) - 0.4783(Model S2) \n",
      "830\n",
      "210\n",
      "640\n",
      "Query 23: 0.5470(Model A)    |     0.5596(Model S1) - 0.5207(Model S2) \n",
      "840\n",
      "210\n",
      "810\n",
      "Query 24: 0.5026(Model A)    |     0.5552(Model S1) - 0.5019(Model S2) \n",
      "790\n",
      "200\n",
      "690\n",
      "Query 25: 0.5180(Model A)    |     0.5565(Model S1) - 0.5201(Model S2) \n",
      "620\n",
      "190\n",
      "700\n",
      "Query 26: 0.5253(Model A)    |     0.5530(Model S1) - 0.5222(Model S2) \n",
      "740\n",
      "200\n",
      "660\n",
      "Query 27: 0.5320(Model A)    |     0.5514(Model S1) - 0.5024(Model S2) \n",
      "670\n",
      "220\n",
      "650\n",
      "Query 28: 0.5441(Model A)    |     0.5524(Model S1) - 0.5428(Model S2) \n",
      "740\n",
      "200\n",
      "670\n",
      "Query 29: 0.5485(Model A)    |     0.5608(Model S1) - 0.5196(Model S2) \n",
      "680\n",
      "230\n",
      "640\n",
      "Query 30: 0.5276(Model A)    |     0.5349(Model S1) - 0.4984(Model S2) \n",
      "750\n",
      "250\n",
      "800\n",
      "Query 31: 0.5427(Model A)    |     0.5543(Model S1) - 0.4947(Model S2) \n",
      "650\n",
      "240\n",
      "590\n",
      "Query 32: 0.4826(Model A)    |     0.5259(Model S1) - 0.5320(Model S2) \n",
      "650\n",
      "220\n",
      "570\n",
      "Query 33: 0.5545(Model A)    |     0.5297(Model S1) - 0.4841(Model S2) \n",
      "680\n",
      "210\n",
      "560\n",
      "Query 34: 0.4836(Model A)    |     0.5257(Model S1) - 0.5096(Model S2) \n",
      "560\n",
      "180\n",
      "610\n",
      "Query 35: 0.5263(Model A)    |     0.5188(Model S1) - 0.4887(Model S2) \n",
      "660\n",
      "230\n",
      "610\n",
      "Query 36: 0.4744(Model A)    |     0.5433(Model S1) - 0.5477(Model S2) \n",
      "610\n",
      "190\n",
      "550\n",
      "Query 37: 0.4994(Model A)    |     0.5363(Model S1) - 0.5587(Model S2) \n",
      "710\n",
      "210\n",
      "650\n",
      "Query 38: 0.5226(Model A)    |     0.5403(Model S1) - 0.5694(Model S2) \n",
      "690\n",
      "230\n",
      "600\n",
      "Query 39: 0.5619(Model A)    |     0.5473(Model S1) - 0.5273(Model S2) \n",
      "720\n",
      "210\n",
      "650\n",
      "Query 40: 0.5385(Model A)    |     0.5541(Model S1) - 0.5467(Model S2) \n",
      "670\n",
      "190\n",
      "650\n",
      "Query 41: 0.5361(Model A)    |     0.5355(Model S1) - 0.4585(Model S2) \n",
      "590\n",
      "240\n",
      "570\n",
      "Query 42: 0.5191(Model A)    |     0.5643(Model S1) - 0.4985(Model S2) \n",
      "610\n",
      "230\n",
      "610\n",
      "Query 43: 0.5824(Model A)    |     0.5652(Model S1) - 0.4881(Model S2) \n",
      "630\n",
      "200\n",
      "560\n",
      "Query 44: 0.5264(Model A)    |     0.5583(Model S1) - 0.5290(Model S2) \n",
      "690\n",
      "190\n",
      "580\n",
      "Query 45: 0.5762(Model A)    |     0.5690(Model S1) - 0.5631(Model S2) \n",
      "670\n",
      "210\n",
      "610\n",
      "Query 46: 0.5932(Model A)    |     0.5675(Model S1) - 0.5343(Model S2) \n",
      "560\n",
      "210\n",
      "510\n",
      "Query 47: 0.5488(Model A)    |     0.5706(Model S1) - 0.5441(Model S2) \n",
      "530\n",
      "210\n",
      "580\n",
      "Query 48: 0.5705(Model A)    |     0.5705(Model S1) - 0.5538(Model S2) \n",
      "620\n",
      "210\n",
      "560\n",
      "Query 49: 0.5376(Model A)    |     0.5815(Model S1) - 0.5797(Model S2) \n",
      "660\n",
      "190\n",
      "600\n",
      "Query 50: 0.5596(Model A)    |     0.5759(Model S1) - 0.5537(Model S2) \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_917b93c4-d1c5-4926-bb7d-b498d4663025\", \"res_bald_A2.npy\", 2336)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A2 BALD\n",
    "acquisition_hist, successor1_hist, successor2_hist, scores, pool_idx = active_learning_procedure(\n",
    "                                                                                X_test,\n",
    "                                                                                y_test,\n",
    "                                                                                X_pool,\n",
    "                                                                                y_pool,\n",
    "                                                                                X_initial,\n",
    "                                                                                y_initial,\n",
    "                                                                                n_queries = 20,\n",
    "                                                                                n_instances = 1,\n",
    "                                                                                Model_A = 2, Model_S1 = 1, Model_S2 = 3)\n",
    "with open('res_bald_A2.npy', 'wb') as f:\n",
    "    np.save(f, acquisition_hist)\n",
    "    np.save(f, successor1_hist)\n",
    "    np.save(f, successor2_hist)\n",
    "    np.save(f, scores)\n",
    "\n",
    "from google.colab import files\n",
    "files.download('res_bald_A2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "el4pBQvofl5i",
    "outputId": "bafceb2e-02c4-462d-b1a0-d843ba73a900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530\n",
      "210\n",
      "190\n",
      "999\n",
      "350\n",
      "250\n",
      "Query 1: 0.3878(Model A)    |     0.2449(Model S1) - 0.3684(Model S2) \n",
      "999\n",
      "280\n",
      "260\n",
      "Query 2: 0.3567(Model A)    |     0.3977(Model S1) - 0.3832(Model S2) \n",
      "999\n",
      "300\n",
      "280\n",
      "Query 3: 0.4006(Model A)    |     0.4181(Model S1) - 0.3959(Model S2) \n",
      "800\n",
      "999\n",
      "260\n",
      "Query 4: 0.3778(Model A)    |     0.4572(Model S1) - 0.4577(Model S2) \n",
      "720\n",
      "250\n",
      "210\n",
      "Query 5: 0.4226(Model A)    |     0.4526(Model S1) - 0.4387(Model S2) \n",
      "990\n",
      "250\n",
      "260\n",
      "Query 6: 0.4475(Model A)    |     0.4891(Model S1) - 0.4732(Model S2) \n",
      "900\n",
      "240\n",
      "220\n",
      "Query 7: 0.4692(Model A)    |     0.4693(Model S1) - 0.4588(Model S2) \n",
      "740\n",
      "280\n",
      "250\n",
      "Query 8: 0.4467(Model A)    |     0.4769(Model S1) - 0.4578(Model S2) \n",
      "740\n",
      "240\n",
      "260\n",
      "Query 9: 0.4930(Model A)    |     0.4795(Model S1) - 0.4824(Model S2) \n",
      "670\n",
      "270\n",
      "240\n",
      "Query 10: 0.4327(Model A)    |     0.4784(Model S1) - 0.4785(Model S2) \n",
      "870\n",
      "240\n",
      "270\n",
      "Query 11: 0.4496(Model A)    |     0.5114(Model S1) - 0.5063(Model S2) \n",
      "850\n",
      "999\n",
      "190\n",
      "Query 12: 0.4453(Model A)    |     0.4786(Model S1) - 0.5130(Model S2) \n",
      "770\n",
      "850\n",
      "240\n",
      "Query 13: 0.4649(Model A)    |     0.5205(Model S1) - 0.5225(Model S2) \n",
      "810\n",
      "850\n",
      "240\n",
      "Query 14: 0.4900(Model A)    |     0.5135(Model S1) - 0.5389(Model S2) \n",
      "600\n",
      "880\n",
      "250\n",
      "Query 15: 0.4634(Model A)    |     0.5191(Model S1) - 0.5418(Model S2) \n",
      "530\n",
      "910\n",
      "180\n",
      "Query 16: 0.5216(Model A)    |     0.5366(Model S1) - 0.5583(Model S2) \n",
      "770\n",
      "660\n",
      "240\n",
      "Query 17: 0.5168(Model A)    |     0.5133(Model S1) - 0.5613(Model S2) \n",
      "550\n",
      "640\n",
      "220\n",
      "Query 18: 0.4770(Model A)    |     0.5407(Model S1) - 0.5560(Model S2) \n",
      "580\n",
      "830\n",
      "200\n",
      "Query 19: 0.4708(Model A)    |     0.5115(Model S1) - 0.5513(Model S2) \n",
      "690\n",
      "760\n",
      "200\n",
      "Query 20: 0.5437(Model A)    |     0.5442(Model S1) - 0.5707(Model S2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_1127f898-33b4-492a-904d-85464cafda5a\", \"res_bald_A3.npy\", 146795)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A3 BALD\n",
    "acquisition_hist, successor1_hist, successor2_hist, scores, pool_idx = active_learning_procedure(\n",
    "                                                                                X_test,\n",
    "                                                                                y_test,\n",
    "                                                                                X_pool,\n",
    "                                                                                y_pool,\n",
    "                                                                                X_initial,\n",
    "                                                                                y_initial,\n",
    "                                                                                n_queries = 20,\n",
    "                                                                                n_instances = 1,\n",
    "                                                                                Model_A = 3, Model_S1 = 2, Model_S2 = 1)\n",
    "with open('res_bald_A3.npy', 'wb') as f:\n",
    "    np.save(f, acquisition_hist)\n",
    "    np.save(f, successor1_hist)\n",
    "    np.save(f, successor2_hist)\n",
    "    np.save(f, scores)\n",
    "\n",
    "from google.colab import files\n",
    "files.download('res_bald_A3.npy')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of VI_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "019a04bb23a54af48ce2f3b7b3992504": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08b8ad52bb694d59a9d288230706e856": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c4c30db3eb74663b1427165d47fc48b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0df7f791902b471f97b7d3431cccae60": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f552b2a0366f47758132545a7f86d25b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_df39be5b13ec4dbf97e6bff3b7857761",
      "value": " 1649664/? [00:48&lt;00:00, 33740.70it/s]"
     }
    },
    "17ebeed3f1f54107a5265cbebf3cd72a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18b8cde1c1284928a66edcc14d656276": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bc2a174b92c485dbc2f3d010eed9452": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b34c5425c6e4c5aa754b30af6b17188",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_019a04bb23a54af48ce2f3b7b3992504",
      "value": " 29696/? [00:49&lt;00:00, 602.32it/s]"
     }
    },
    "1e2b0b9c30d247c2b024b0f9235d52a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "220f73e8acba41ae958d23613648bd73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2eb18081ddd943be94b052bdb0a4c21e",
       "IPY_MODEL_717081bc4d2545e09010e12a0a69cc73"
      ],
      "layout": "IPY_MODEL_dac56640b523457286bfce618cb5b3ff"
     }
    },
    "2eaefb7459374adaaf303ccb62977e80": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eb18081ddd943be94b052bdb0a4c21e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c4c30db3eb74663b1427165d47fc48b",
      "max": 4542,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_848274ab7fca43c992b9343072041534",
      "value": 4542
     }
    },
    "335849cddce44cabaac42aa144c6a36d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "46cb5e25c9424d6b94e38d188816c64a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5688c2a58f79455fb66605ec637cf0d2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60a79628153b4db087849ba72a954356": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bbbb11244294ad3a4b391e69b07bb58",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_46cb5e25c9424d6b94e38d188816c64a",
      "value": " 9913344/? [05:42&lt;00:00, 28953.19it/s]"
     }
    },
    "717081bc4d2545e09010e12a0a69cc73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08b8ad52bb694d59a9d288230706e856",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1e2b0b9c30d247c2b024b0f9235d52a0",
      "value": " 5120/? [00:00&lt;00:00, 22599.83it/s]"
     }
    },
    "827da8f3618f4e33b967a74416f6d32f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5688c2a58f79455fb66605ec637cf0d2",
      "max": 9912422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_98796061537b4a08892a73e1df95d3f2",
      "value": 9912422
     }
    },
    "848274ab7fca43c992b9343072041534": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "88335236f2e74acf86186ea07a8748c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b34c5425c6e4c5aa754b30af6b17188": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e8e0c29f08c41e58a5ef1c538942944": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_827da8f3618f4e33b967a74416f6d32f",
       "IPY_MODEL_60a79628153b4db087849ba72a954356"
      ],
      "layout": "IPY_MODEL_17ebeed3f1f54107a5265cbebf3cd72a"
     }
    },
    "92866e9dc5de4675a4e2654b41979159": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9776a5019da043bda3c34304446c6468",
       "IPY_MODEL_1bc2a174b92c485dbc2f3d010eed9452"
      ],
      "layout": "IPY_MODEL_88335236f2e74acf86186ea07a8748c1"
     }
    },
    "9776a5019da043bda3c34304446c6468": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18b8cde1c1284928a66edcc14d656276",
      "max": 28881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_335849cddce44cabaac42aa144c6a36d",
      "value": 28881
     }
    },
    "98796061537b4a08892a73e1df95d3f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9af1a4b5971246ecae0c3184b966447e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf1d10e818a54ac58d663c03fc7ec8ec",
       "IPY_MODEL_0df7f791902b471f97b7d3431cccae60"
      ],
      "layout": "IPY_MODEL_2eaefb7459374adaaf303ccb62977e80"
     }
    },
    "9bbbb11244294ad3a4b391e69b07bb58": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf1d10e818a54ac58d663c03fc7ec8ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c86775d73992432ebc2bcd2d4ddf7dca",
      "max": 1648877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c993739faef6407283c097746d6ab487",
      "value": 1648877
     }
    },
    "c86775d73992432ebc2bcd2d4ddf7dca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c993739faef6407283c097746d6ab487": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dac56640b523457286bfce618cb5b3ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df39be5b13ec4dbf97e6bff3b7857761": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f552b2a0366f47758132545a7f86d25b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
