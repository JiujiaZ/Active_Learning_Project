{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tD9Ga46BWZ8w"
   },
   "source": [
    "Aim: initial size = 10, find setting AL is superior than IID, use default lr\n",
    "<br> \n",
    "Try: (1) n = 1, mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pj8JwyyFdQvo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, distributions\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819,
     "referenced_widgets": [
      "54ddd446c8c547ae9b70da4f20350259",
      "bc9832a8f3944333b0e7a500bf030084",
      "c960465d06cd4a018834f964fe098373",
      "d7eede79b5e04dfeaba41490f9dc378f",
      "dc5c8217441b439980dc5f042ac50c3e",
      "511af83aeba1488897d2cff3b477bdc8",
      "20feae755dad40728314b73c5597190f",
      "4f9cb9be49ab48e7b36a680e2830a130",
      "7a84aecefa8744359710be1e6bf2107a",
      "2e6d92897705487d917b7b2115a75216",
      "bbd84446f4174fe49e628369b4aee077",
      "550efb7acd39429c8c48c7a5c1976a78",
      "24d11fd8db6e46958b0e4cb53126f9f7",
      "ca122b207f2d4c90b9e9119af9a0fc0d",
      "6a5a761c9dc04a1c9d7751e21a81f5d7",
      "839891b6adfa46f5aae58ee71d0fd15c",
      "064ed0f2746542eab159676f143a8fda",
      "99c0825de8e746db8dc4e5af38bd16fa",
      "42b57a85269d4097bea4732dd89df437",
      "5575a9af1ddb432d81995c2170d5d59f",
      "5dae32f55bc64e348d5c01204c4a84c9",
      "a3dc2d9352384c11823eee607c854cce",
      "210a6f76fd77403ebd788eb544fe1671",
      "b275a2aa837349a7b1d912e69286e917",
      "7218851bd204444aa887e0e094b8506f",
      "16fc57603dce4b8aa6e1de8fe8402d26",
      "03fa8fa1e39e4399a6b8b51574bb8111",
      "c7762d684bb143b895a527f0872cbf79",
      "08ec92006dea47eba9b4ed2f0db1276a",
      "0ab2de4d902d4c56a61692f0a690bdd7",
      "31a5d349ec3c498d83b23c5b3736b168",
      "3d68c35ed769410cbbcc0606c39c0b54"
     ]
    },
    "id": "WvJsuwgRdQvr",
    "outputId": "37274686-40f3-4041-d0aa-1c7f9cfcd707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ddd446c8c547ae9b70da4f20350259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a84aecefa8744359710be1e6bf2107a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064ed0f2746542eab159676f143a8fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7218851bd204444aa887e0e094b8506f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = datasets.MNIST(\"../data\", train=True, download=True, transform=ToTensor())\n",
    "mnist_test  = datasets.MNIST(\"../data\", train=False,download=True, transform=ToTensor())\n",
    "traindataloader = DataLoader(mnist_train, shuffle=True, batch_size=60000)\n",
    "testdataloader  = DataLoader(mnist_test , shuffle=True, batch_size=10000)\n",
    "X_train, y_train = next(iter(traindataloader))\n",
    "X_test , y_test  = next(iter(testdataloader))\n",
    "\n",
    "X_train = X_train.reshape(60000, -1)\n",
    "X_test = X_test.reshape(10000, -1)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AJDDsAzIWpfk"
   },
   "outputs": [],
   "source": [
    "# sepeate train data into (1) initial, (2) pool\n",
    "initial_idx = np.array([],dtype=int)\n",
    "for i in range(10):\n",
    "    idx = np.random.choice(np.where(y_train==i)[0], size=1, replace=False)\n",
    "    initial_idx = np.concatenate((initial_idx, idx))\n",
    "\n",
    "X_initial = X_train[initial_idx]\n",
    "y_initial = y_train[initial_idx]\n",
    "\n",
    "X_pool = np.delete(X_train, initial_idx, axis=0)\n",
    "y_pool = np.delete(y_train, initial_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueGHFnNHW8lH"
   },
   "outputs": [],
   "source": [
    "# BALD Acquisition function (incomplete sampling in paper)\n",
    "def bald(model_A, model_S1, model_S2, X, n_instances, T = 100):\n",
    "  \n",
    "    random_subset = np.random.choice(range(len(X)), size=len(X), replace=False)\n",
    "    with torch.no_grad():\n",
    "        x = X[random_subset].to(device)\n",
    "        outputs = np.stack([torch.exp(model_A(x)).detach().cpu().numpy() for t in range(T)])\n",
    "\n",
    "    pc = outputs.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(outputs * np.log(outputs + 1e-10), axis=-1), axis=0) \n",
    "    acquisition = H - E_H\n",
    "    idx = (-acquisition).argsort()[:n_instances]\n",
    "    query_idx = random_subset[idx]\n",
    "\n",
    "    score_A = acquisition[query_idx]\n",
    "    \n",
    "    #---------------- score for successors:\n",
    "    with torch.no_grad():\n",
    "        output_S1 = np.stack([torch.exp(model_S1(X[query_idx].to(device))).detach().cpu().numpy() for t in range(T)])\n",
    "        output_S2 = np.stack([torch.exp(model_S2(X[query_idx].to(device))).detach().cpu().numpy() for t in range(T)])\n",
    "\n",
    "    pc = output_S1.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(output_S1 * np.log(output_S1 + 1e-10), axis=-1), axis=0) \n",
    "    score_S1 = H - E_H\n",
    "\n",
    "    pc = output_S2.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(output_S2 * np.log(output_S2 + 1e-10), axis=-1), axis=0) \n",
    "    score_S2 = H - E_H\n",
    "\n",
    "    return (query_idx, score_A, score_S1, score_S2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qqpHId4kpXS0"
   },
   "outputs": [],
   "source": [
    "# BALD Acquisition function (in use)\n",
    "def bald(model_A, model_S1, model_S2, X, n_instances, T = 100):\n",
    "    with torch.no_grad():\n",
    "        x = X.to(device)\n",
    "        outputs = np.stack([torch.exp(model_A(x, eval = True)).detach().cpu().numpy() for t in range(T)])\n",
    "\n",
    "    pc = outputs.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(outputs * np.log(outputs + 1e-10), axis=-1), axis=0) \n",
    "    acquisition = H - E_H\n",
    "    query_idx = (-acquisition).argsort()[:n_instances]\n",
    "\n",
    "    score_A = acquisition[query_idx]\n",
    "    \n",
    "    #---------------- score for successors:\n",
    "    with torch.no_grad():\n",
    "        output_S1 = np.stack([torch.exp(model_S1(X[query_idx].to(device), eval = True)).detach().cpu().numpy() for t in range(T)])\n",
    "        output_S2 = np.stack([torch.exp(model_S2(X[query_idx].to(device), eval = True)).detach().cpu().numpy() for t in range(T)])\n",
    "\n",
    "    pc = output_S1.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(output_S1 * np.log(output_S1 + 1e-10), axis=-1), axis=0) \n",
    "    score_S1 = H - E_H\n",
    "\n",
    "    pc = output_S2.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(output_S2 * np.log(output_S2 + 1e-10), axis=-1), axis=0) \n",
    "    score_S2 = H - E_H\n",
    "\n",
    "    return (query_idx, score_A, score_S1, score_S2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FT5L2GeRrKW0"
   },
   "outputs": [],
   "source": [
    "# IID acquistion:\n",
    "def iid_acq(model_A, model_S1, model_S2, X, n_instances, T = 100):\n",
    "\n",
    "    query_idx = np.random.choice(range(len(X)), size=n_instances, replace=False)\n",
    "    with torch.no_grad():\n",
    "        x = X[query_idx].to(device)\n",
    "        outputs = np.stack([torch.exp(model_A(x, eval = True)).detach().cpu().numpy() for t in range(T)])\n",
    "        output_S1 = np.stack([torch.exp(model_S1(x, eval = True)).detach().cpu().numpy() for t in range(T)])\n",
    "        output_S2 = np.stack([torch.exp(model_S2(x, eval = True)).detach().cpu().numpy() for t in range(T)])\n",
    "\n",
    "    pc = outputs.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(outputs * np.log(outputs + 1e-10), axis=-1), axis=0) \n",
    "    score_A = H - E_H\n",
    "    \n",
    "    #---------------- score for the other 2 models:\n",
    "    pc = output_S1.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(output_S1 * np.log(output_S1 + 1e-10), axis=-1), axis=0) \n",
    "    score_S1 = H - E_H\n",
    "\n",
    "    pc = output_S2.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(output_S2 * np.log(output_S2 + 1e-10), axis=-1), axis=0) \n",
    "    score_S2 = H - E_H\n",
    "\n",
    "    return (query_idx, score_A, score_S1, score_S2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "rgnC6nsEamBZ"
   },
   "outputs": [],
   "source": [
    "def active_learning_procedure(X_test,\n",
    "                              y_test,\n",
    "                              X_pool,\n",
    "                              y_pool,\n",
    "                              X_initial,\n",
    "                              y_initial,\n",
    "                              n_queries=100, \n",
    "                              n_instances=1,\n",
    "                              sample_strategy = 'bald',\n",
    "                              Model_A = 1,\n",
    "                              Model_S1 = 2,\n",
    "                              Model_S2 = 3):\n",
    "\n",
    "    pool_idx = list()\n",
    "    train_ls = list()\n",
    "    x_train_sample = X_initial\n",
    "    y_train_sample = y_initial\n",
    "    train_loader = DataLoader(list(zip(x_train_sample,  y_train_sample)), \n",
    "                      shuffle=True, batch_size = 10)\n",
    "\n",
    "    #valid_idx = np.random.randint(0, len(y_pool), len(x_train_sample))\n",
    "    #x_valid = X_pool[valid_idx]\n",
    "    #y_valid = y_pool[valid_idx]\n",
    "\n",
    "    #valid_loader = DataLoader(list(zip(x_valid,  y_valid)), \n",
    "    #                  shuffle=False, batch_size = len(x_valid))\n",
    "  \n",
    "    early_epoch = 100\n",
    "    max_epoch = 500\n",
    "\n",
    "    #----- Model A --------------------------\n",
    "    if (Model_A==1):\n",
    "        A = Model1(784, 10, n_batch = len(train_loader)).to(device)\n",
    "        #early_epoch = 100\n",
    "    elif (Model_A ==2 ):\n",
    "        A = Model2(784, 392, 10, n_batch = len(train_loader)).to(device)\n",
    "        #early_epoch = 200\n",
    "    elif (Model_A == 3):\n",
    "        A = Model3(784, [392, 196], 10, n_batch = len(train_loader)).to(device)\n",
    "        #early_epoch = 500\n",
    "    else:\n",
    "        print('Invalid option for Model_A')\n",
    "        return\n",
    "    A.reset_bs()\n",
    "    optim0 = torch.optim.Adam(A.parameters(), lr=0.001)\n",
    "    ls, acc = train(A, optim0, max_epoch, train_loader, X_test, y_test, early_epoch, verbose = False)\n",
    "    acquisition_hist  = [acc]\n",
    "    #train_ls.append(ls)\n",
    "\n",
    "    #----- Model S --------------------------\n",
    "    if (Model_S1 == 1):\n",
    "        S1 = Model1(784, 10, n_batch = len(train_loader)).to(device)\n",
    "        #early_epoch = 100\n",
    "    elif (Model_S1 ==2):\n",
    "        S1 = Model2(784, 392, 10, n_batch = len(train_loader)).to(device)\n",
    "        #early_epoch = 200\n",
    "    else:\n",
    "        print('Invalid option for Model_S1')\n",
    "        return\n",
    "    S1.reset_bs()\n",
    "    optim1 = torch.optim.Adam(S1.parameters(), lr=0.001)\n",
    "    _, acc = train(S1, optim1, max_epoch, train_loader, X_test, y_test, early_epoch, verbose = False)\n",
    "    successor1_hist = [acc]\n",
    "\n",
    "    if (Model_S2 == 1):\n",
    "        S2 = Model1(784, 10, n_batch = len(train_loader)).to(device)\n",
    "        #early_epoch = 100\n",
    "    elif (Model_S2 ==3):\n",
    "        S2 = Model3(784, [392, 196], 10, n_batch = len(train_loader)).to(device)\n",
    "        #early_epoch = 500\n",
    "    else:\n",
    "        print('Invalid option for Model_A')\n",
    "        return\n",
    "    S2.reset_bs()  \n",
    "    optim2 = torch.optim.Adam(S2.parameters(), lr=0.001)\n",
    "    ls, acc = train(S2, optim2, max_epoch,  train_loader, X_test, y_test, early_epoch, verbose = False)\n",
    "    successor2_hist = [acc]\n",
    "    train_ls.append(ls)\n",
    "\n",
    "    scores = list()\n",
    "\n",
    "    for index in range(n_queries):\n",
    "        # for incomplete sampling (paper):\n",
    "        #query_idx = np.concatenate([bald(A, X_pool) for n in range(n_instances)])\n",
    "\n",
    "        # for complete set sampling:\n",
    "        if (sample_strategy  == 'bald'):\n",
    "            query_idx, score_A, score_S1, score_S2 = bald(A, S1, S2, X_pool, n_instances)\n",
    "        elif (sample_strategy == 'iid'):\n",
    "            query_idx, score_A, score_S1, score_S2 = iid_acq(A, S1, S2, X_pool, n_instances)\n",
    "        else:\n",
    "            print('Unexpected sampling strategy')\n",
    "            break\n",
    "        \n",
    "        # record scores:\n",
    "        scores.append(np.vstack((score_A, score_S1, score_S2)))\n",
    "\n",
    "        x_train_sample = torch.vstack((x_train_sample, X_pool[query_idx]))\n",
    "        y_train_sample = torch.cat((y_train_sample,y_pool[query_idx]))\n",
    "        train_loader = DataLoader(list(zip(x_train_sample,  y_train_sample)), \n",
    "                      shuffle=True, batch_size = 10)\n",
    "\n",
    "        #valid_idx = np.random.randint(0, len(y_pool), len(x_train_sample))\n",
    "        #x_valid = X_pool[valid_idx]\n",
    "        #y_valid = y_pool[valid_idx]\n",
    "        #valid_loader = DataLoader(list(zip(x_valid,  y_valid)), \n",
    "        #              shuffle=False, batch_size = len(x_valid))\n",
    "\n",
    "        # model A:\n",
    "        if (Model_A==1):\n",
    "            A = Model1(784, 10, n_batch = len(train_loader)).to(device)\n",
    "            #early_epoch = 100\n",
    "        elif (Model_A ==2 ):\n",
    "            A = Model2(784, 392, 10, n_batch = len(train_loader)).to(device)\n",
    "            #early_epoch = 200\n",
    "        elif (Model_A == 3):\n",
    "            A = Model3(784, [392, 196], 10, n_batch = len(train_loader)).to(device)\n",
    "            #early_epoch = 500\n",
    "        else:\n",
    "            print('Invalid option for Model_A')\n",
    "            return\n",
    "        A.reset_bs()\n",
    "        optim0 = torch.optim.Adam(A.parameters(), lr=0.001)\n",
    "        ls, acc = train(A, optim0, max_epoch, train_loader, X_test, y_test, early_epoch, verbose = False)\n",
    "        acquisition_hist.append(acc)\n",
    "        #train_ls.append(ls)\n",
    "\n",
    "        # model S:\n",
    "        if (Model_S1 == 1):\n",
    "            S1 = Model1(784, 10, n_batch = len(train_loader)).to(device)\n",
    "            #early_epoch = 100\n",
    "        elif (Model_S1 ==2):\n",
    "            S1 = Model2(784, 392, 10, n_batch = len(train_loader)).to(device)\n",
    "            #early_epoch = 200\n",
    "        else:\n",
    "            print('Invalid option for Model_S1')\n",
    "            return\n",
    "        S1.reset_bs()\n",
    "        optim1 = torch.optim.Adam(S1.parameters(), lr=0.001)\n",
    "        _, acc = train(S1, optim1, max_epoch,  train_loader, X_test, y_test, early_epoch, verbose = False)\n",
    "        successor1_hist.append(acc)\n",
    "\n",
    "        if (Model_S2 == 1):\n",
    "            S2 = Model1(784, 10, n_batch = len(train_loader)).to(device)\n",
    "            #early_epoch = 100\n",
    "        elif (Model_S2 ==3):\n",
    "            S2 = Model3(784, [392, 196], 10, n_batch = len(train_loader)).to(device)\n",
    "            #early_epoch = 500\n",
    "        else:\n",
    "            print('Invalid option for Model_A')\n",
    "            return  \n",
    "        S2.reset_bs()\n",
    "        optim2 = torch.optim.Adam(S2.parameters(), lr=0.001)\n",
    "        ls, acc = train(S2, optim2, max_epoch, train_loader, X_test, y_test, early_epoch, verbose = False)\n",
    "        successor2_hist.append(acc)\n",
    "        train_ls.append(ls)\n",
    "\n",
    "        \n",
    "        # delete queried data from pool:\n",
    "        X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "        y_pool = np.delete(y_pool, query_idx, axis=0)\n",
    "\n",
    "        print('Query {n}: {acc:0.4f}(Model A)    |     {acc_s1:0.4f}(Model S1) - {acc_s2:0.4f}(Model S2) '.format(n=index + 1, \n",
    "                                                                                                                  acc=acquisition_hist[-1], \n",
    "                                                                                                                  acc_s1 = successor1_hist[-1], \n",
    "                                                                                                                  acc_s2 = successor2_hist[-1]))     \n",
    "        pool_idx.append(query_idx)\n",
    "    return(acquisition_hist, successor1_hist, successor2_hist, scores, pool_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "P01kRIEGdQvs"
   },
   "outputs": [],
   "source": [
    "class LinearVariational(nn.Module):\n",
    "    def __init__(self, in_features, out_features, loss_accumulator, batch_num, n_batch, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.include_bias = bias        \n",
    "        self.loss_accumulator = loss_accumulator\n",
    "        self.n_batch = n_batch\n",
    "        self.batch_num = batch_num\n",
    "        \n",
    "        if getattr(loss_accumulator, 'accumulated_kl_div', None) is None:\n",
    "            loss_accumulator.accumulated_kl_div = 0\n",
    "        if getattr(batch_num, 'accumulated_bs', None) is None:\n",
    "            batch_num.accumulated_bs = 0\n",
    "\n",
    "        # mean:\n",
    "        self.w_mu = nn.Parameter(\n",
    "            torch.FloatTensor(in_features, out_features).normal_(mean=0, std=0.001)\n",
    "        )\n",
    "         \n",
    "        # variance log(1 + exp(p))◦ eps:\n",
    "        self.w_p = nn.Parameter(\n",
    "            torch.FloatTensor(in_features, out_features).normal_(mean=-2.5, std=0.001)\n",
    "        )\n",
    "        if self.include_bias:\n",
    "            self.b_mu = nn.Parameter(\n",
    "                torch.zeros(out_features)\n",
    "            )\n",
    "            self.b_p = nn.Parameter(\n",
    "                torch.zeros(out_features)\n",
    "            )\n",
    "        \n",
    "    def reparameterize(self, mu, p):\n",
    "        sigma = torch.log(1 + torch.exp(p)) \n",
    "        eps = torch.randn_like(sigma)\n",
    "        return mu + (eps * sigma)\n",
    "    \n",
    "    def kl_divergence(self, z, mu_theta, p_theta, batch_num, prior_sd=1):\n",
    "        log_prior = distributions.Normal(0, prior_sd).log_prob(z) \n",
    "        log_p_q = distributions.Normal(mu_theta, torch.log(1 + torch.exp(p_theta))).log_prob(z) \n",
    "        weights =  np.power(2,self.n_batch - batch_num) /  (np.power(2,self.n_batch)-1) \n",
    "\n",
    "        #print('batch_num {}: weights {}'.format(batch_num, weights))\n",
    "        return (log_p_q - log_prior).mean() * weights\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.reparameterize(self.w_mu, self.w_p)\n",
    "        \n",
    "        if self.include_bias:\n",
    "            b = self.reparameterize(self.b_mu, self.b_p)\n",
    "        else:\n",
    "            b = 0\n",
    "            \n",
    "        z = x @ w + b\n",
    "        \n",
    "        if (self.batch_num.clip == False):\n",
    "            self.batch_num.accumulated_bs += 1\n",
    "        self.loss_accumulator.accumulated_kl_div += self.kl_divergence(w, \n",
    "                                                             self.w_mu,\n",
    "                                                             self.w_p,\n",
    "                                                             self.batch_num.accumulated_bs\n",
    "                                                             )\n",
    "        if self.include_bias:\n",
    "            self.loss_accumulator.accumulated_kl_div += self.kl_divergence(b, \n",
    "                                                                 self.b_mu, \n",
    "                                                                 self.b_p,\n",
    "                                                                 self.batch_num.accumulated_bs\n",
    "                                                                 )\n",
    "        return z\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class KL:\n",
    "    accumulated_kl_div = 0\n",
    "class BS:\n",
    "    accumulated_bs = 0\n",
    "    clip = False\n",
    "\n",
    "def det_loss(y, y_pred, model):\n",
    "    reconstruction_error = F.nll_loss(y_pred, y,reduction=\"mean\")\n",
    "    kl = model.accumulated_kl_div\n",
    "    #model.reset_kl_div() # reset fo each batch\n",
    "    #model.reset_bs()\n",
    "    #print('rec: {} | kl: {}'.format(reconstruction_error, kl))\n",
    "    #print('loss {}'.format(reconstruction_error + kl))\n",
    "    return reconstruction_error + kl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "qf0y3IYxtkIk"
   },
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self, in_size, out_size, n_batch):\n",
    "        super().__init__()\n",
    "        self.kl_loss = KL\n",
    "        self.bs_num = BS\n",
    "\n",
    "        self.var = LinearVariational(in_size, out_size, self.kl_loss, self.bs_num, n_batch)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.log_softmax = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            LinearVariational(in_size, out_size, self.kl_loss, self.bs_num, n_batch),\n",
    "            nn.LogSoftmax(dim = 1)\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def accumulated_kl_div(self):\n",
    "        return self.kl_loss.accumulated_kl_div\n",
    "    \n",
    "    def reset_kl_div(self):\n",
    "        self.kl_loss.accumulated_kl_div = 0\n",
    "\n",
    "    def accumulated_bs(self):\n",
    "        return self.bs_num.accumulated_bs\n",
    "    \n",
    "    def reset_bs(self):\n",
    "        self.bs_num.accumulated_bs = 0\n",
    "    \n",
    "    def clip_bs(self, clip = True):\n",
    "        self.bs_num.clip = clip\n",
    "    \n",
    "    def set_bs(self, val):\n",
    "        self.bs_num.accumulated_bs = val\n",
    "            \n",
    "    def forward(self, x, eval = False):\n",
    "        if eval:\n",
    "            Model1.set_bs(self, val = 1)\n",
    "            Model1.clip_bs(self, clip = True)\n",
    "        else:\n",
    "            Model1.clip_bs(self, clip = False)\n",
    "        out = self.var(x)\n",
    "        out = self.log_softmax(out)\n",
    "        return out\n",
    "\n",
    "class Model2(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size, n_batch):\n",
    "        super().__init__()\n",
    "        self.kl_loss = KL\n",
    "        self.bs_num = BS\n",
    "        \n",
    "        self.var1 = LinearVariational(in_size, hidden_size, self.kl_loss, self.bs_num, n_batch)\n",
    "        self.lin1 = nn.Linear(in_size, hidden_size)\n",
    "        self.var2 = LinearVariational(hidden_size, out_size, self.kl_loss, self.bs_num, n_batch)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.log_softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def accumulated_kl_div(self):\n",
    "        return self.kl_loss.accumulated_kl_div\n",
    "    \n",
    "    def reset_kl_div(self):\n",
    "        self.kl_loss.accumulated_kl_div = 0\n",
    "\n",
    "    def accumulated_bs(self):\n",
    "        return self.bs_num.accumulated_bs\n",
    "    \n",
    "    def reset_bs(self):\n",
    "        self.bs_num.accumulated_bs = 0\n",
    "\n",
    "    def clip_bs(self, clip = True):\n",
    "        self.bs_num.clip = clip\n",
    "    \n",
    "    def set_bs(self, val):\n",
    "        self.bs_num.accumulated_bs = val\n",
    "            \n",
    "    def forward(self, x, eval = False):\n",
    "        if eval:\n",
    "            Model2.set_bs(self, val = 1)\n",
    "            Model2.clip_bs(self, clip = True)\n",
    "        else:\n",
    "            Model2.clip_bs(self, clip = False)\n",
    "        #out = self.var1(x)   \n",
    "        out = self.lin1(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        #Model2.clip_bs(self)\n",
    "\n",
    "        out = self.var2(out)\n",
    "        out = self.log_softmax(out)\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "class Model3(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size, n_batch):\n",
    "        super().__init__()\n",
    "        self.kl_loss = KL\n",
    "        self.bs_num = BS\n",
    "\n",
    "        self.var1 = LinearVariational(in_size, hidden_size[0], self.kl_loss, self.bs_num, n_batch)\n",
    "        self.var2 = LinearVariational(hidden_size[0], hidden_size[1], self.kl_loss, self.bs_num, n_batch)\n",
    "        self.var3 = LinearVariational(hidden_size[1], out_size, self.kl_loss, self.bs_num, n_batch)\n",
    "\n",
    "        self.lin1 = nn.Linear(in_size, hidden_size[0])\n",
    "        self.lin2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.log_softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def accumulated_kl_div(self):\n",
    "        return self.kl_loss.accumulated_kl_div\n",
    "    \n",
    "    def reset_kl_div(self):\n",
    "        self.kl_loss.accumulated_kl_div = 0\n",
    "\n",
    "    def accumulated_bs(self):\n",
    "        return self.bs_num.accumulated_bs\n",
    "    \n",
    "    def reset_bs(self):\n",
    "        self.bs_num.accumulated_bs = 0\n",
    "\n",
    "    def clip_bs(self, clip = True):\n",
    "        self.bs_num.clip = clip\n",
    "\n",
    "    def set_bs(self, val):\n",
    "        self.bs_num.accumulated_bs = val\n",
    "            \n",
    "    def forward(self, x, eval = False):\n",
    "        if eval:\n",
    "            Model3.set_bs(self, val = 1)\n",
    "            Model3.clip_bs(self, clip = True)\n",
    "        else:\n",
    "            Model3.clip_bs(self, clip = False)\n",
    "        #out = self.var1(x)\n",
    "        out = self.lin1(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        #Model3.clip_bs(self)\n",
    "        #out = self.var2(out)\n",
    "        out = self.lin2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.var3(out)\n",
    "        out = self.log_softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "W_FbZCJ0Bd-E"
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(model, optimizer, num_epoch,\n",
    "          train_loader, \n",
    "          X_test, y_test, early_epoch,\n",
    "          verbose = False):\n",
    "    train_ls = list()\n",
    "    #valid_ls = list()\n",
    "    test_acc = 0\n",
    "    train_kl = list()\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        ls = 0\n",
    "        kl = 0\n",
    "        num_correct = 0\n",
    "        data_num = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch_num, (x, y) in enumerate(train_loader):\n",
    "            #print('in train : batch_num{}'.format(batch_num))\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # forward:\n",
    "            y_pred = model(x, eval = False)\n",
    "            loss = det_loss(y, y_pred, model)\n",
    "            kl += model.accumulated_kl_div\n",
    "            model.reset_kl_div()\n",
    "            ls += loss.item()\n",
    "\n",
    "            # backward:\n",
    "            optimizer.zero_grad() # remove grad from forward prop\n",
    "            loss.backward()\n",
    "\n",
    "            # update gradient:\n",
    "            optimizer.step()\n",
    "\n",
    "            # accuracy:\n",
    "            #_, pred = torch.max(y_pred,1)\n",
    "            #num_correct += (pred == y).sum().item()\n",
    "\n",
    "            data_num += len(y)\n",
    "        #model.reset_bs()\n",
    "\n",
    "        #ls = ls/data_num\n",
    "        #print('valid:')\n",
    "        #val_ls = eval_ls(model, valid_loader)\n",
    "        #weights = np.power(2, len(train_loader)-1) / (np.power(2, len(train_loader)) - 1 )\n",
    "        #weights = 1\n",
    "\n",
    "        #val_ls = val_ls/weights\n",
    "        model.reset_bs()\n",
    "        if verbose:\n",
    "            print(epoch+1)\n",
    "            print(f'\\tLoss: {ls:.4f}(train)\\t')\n",
    "        train_ls.append(ls)\n",
    "        #valid_ls.append(val_ls)\n",
    "        train_kl.append(kl)\n",
    "\n",
    "        # access early stopping:\n",
    "        #trigger = (np.array(train_ls[epoch-50:]) < np.array(valid_ls[epoch-50:])).sum()/500\n",
    "        #if (trigger > 0.5):\n",
    "        #    if verbose:\n",
    "        #        print('Epoch {} : Early Stopping - past 50 epochs half val_ls > train_ls'.format(epoch))\n",
    "        #    test_acc = eval_acc(model, X_test, y_test)\n",
    "        #    break\n",
    "\n",
    "        if ((epoch > early_epoch) & (epoch % 10 == 0)):\n",
    "            mean_1 = np.mean(train_ls[epoch-60:epoch-10])\n",
    "            mean_2 = np.mean(train_ls[epoch-50:])\n",
    "            if (mean_1 - mean_2 < 1e-3):\n",
    "                print(epoch)\n",
    "                test_acc = eval_acc(model, X_test, y_test)\n",
    "                break\n",
    "\n",
    "        if (epoch == num_epoch-1):\n",
    "            print(epoch)\n",
    "            test_acc = eval_acc(model, X_test, y_test)\n",
    "        \n",
    "\n",
    "    return(train_ls, test_acc)\n",
    "\n",
    "\n",
    "def eval_ls(model, loader):\n",
    "    ls = 0\n",
    "    data_num = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = model(x, eval = True)\n",
    "            loss = det_loss(y, y_pred, model)\n",
    "            ls += loss.item()\n",
    "\n",
    "            data_num += len(y)\n",
    "        model.reset_bs()\n",
    "    model.train()\n",
    "    return ls/data_num\n",
    "\n",
    "def eval_acc(model, test_x, test_y):\n",
    "\n",
    "    y_sample = np.stack([torch.exp(model(test_x.to(device), eval = True)).detach().cpu().numpy() for t in range(100)])\n",
    "\n",
    "    y_pred = y_sample.mean(axis = 0).argmax(axis = 1)\n",
    "\n",
    "    #y_sample = model(test_x.to(device)).detach().cpu().numpy()\n",
    "    #y_pred = y_sample.argmax(axis = 1)\n",
    "    acc = np.equal(y_pred, test_y).sum().item()/len(test_y)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "r4LGPvKryZ1k",
    "outputId": "c13ac88d-eb65-45cf-c2c5-5dca3b71bb9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\n",
      "160\n",
      "150\n",
      "450\n",
      "499\n",
      "240\n",
      "Query 1: 0.4710(Model A)    |     0.5095(Model S1) - 0.4993(Model S2) \n",
      "460\n",
      "240\n",
      "260\n",
      "Query 2: 0.4704(Model A)    |     0.4852(Model S1) - 0.4505(Model S2) \n",
      "499\n",
      "499\n",
      "390\n",
      "Query 3: 0.4864(Model A)    |     0.4998(Model S1) - 0.4381(Model S2) \n",
      "499\n",
      "280\n",
      "499\n",
      "Query 4: 0.4514(Model A)    |     0.4704(Model S1) - 0.4573(Model S2) \n",
      "499\n",
      "260\n",
      "220\n",
      "Query 5: 0.4675(Model A)    |     0.5027(Model S1) - 0.4568(Model S2) \n",
      "499\n",
      "270\n",
      "300\n",
      "Query 6: 0.4924(Model A)    |     0.4950(Model S1) - 0.5104(Model S2) \n",
      "499\n",
      "170\n",
      "200\n",
      "Query 7: 0.5233(Model A)    |     0.5250(Model S1) - 0.5129(Model S2) \n",
      "499\n",
      "270\n",
      "160\n",
      "Query 8: 0.5396(Model A)    |     0.5463(Model S1) - 0.5422(Model S2) \n",
      "499\n",
      "210\n",
      "470\n",
      "Query 9: 0.5408(Model A)    |     0.5322(Model S1) - 0.5251(Model S2) \n",
      "499\n",
      "180\n",
      "170\n",
      "Query 10: 0.5386(Model A)    |     0.5439(Model S1) - 0.5087(Model S2) \n",
      "499\n",
      "270\n",
      "360\n",
      "Query 11: 0.5471(Model A)    |     0.5576(Model S1) - 0.5204(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 12: 0.5626(Model A)    |     0.5446(Model S1) - 0.5230(Model S2) \n",
      "499\n",
      "310\n",
      "270\n",
      "Query 13: 0.5641(Model A)    |     0.5709(Model S1) - 0.5170(Model S2) \n",
      "499\n",
      "499\n",
      "200\n",
      "Query 14: 0.5627(Model A)    |     0.5787(Model S1) - 0.5595(Model S2) \n",
      "499\n",
      "330\n",
      "499\n",
      "Query 15: 0.5530(Model A)    |     0.5714(Model S1) - 0.5578(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 16: 0.5398(Model A)    |     0.5677(Model S1) - 0.5544(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 17: 0.5621(Model A)    |     0.5956(Model S1) - 0.5273(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 18: 0.5803(Model A)    |     0.5930(Model S1) - 0.5779(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 19: 0.5692(Model A)    |     0.5929(Model S1) - 0.5696(Model S2) \n",
      "499\n",
      "300\n",
      "210\n",
      "Query 20: 0.5694(Model A)    |     0.5951(Model S1) - 0.5792(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 21: 0.5654(Model A)    |     0.5656(Model S1) - 0.5451(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 22: 0.5650(Model A)    |     0.5889(Model S1) - 0.5570(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 23: 0.5644(Model A)    |     0.5861(Model S1) - 0.5546(Model S2) \n",
      "499\n",
      "499\n",
      "460\n",
      "Query 24: 0.5708(Model A)    |     0.5836(Model S1) - 0.5485(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 25: 0.5779(Model A)    |     0.5961(Model S1) - 0.5438(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 26: 0.5882(Model A)    |     0.6013(Model S1) - 0.5694(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 27: 0.5880(Model A)    |     0.6048(Model S1) - 0.5808(Model S2) \n",
      "499\n",
      "499\n",
      "170\n",
      "Query 28: 0.5890(Model A)    |     0.6083(Model S1) - 0.5076(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 29: 0.5728(Model A)    |     0.5838(Model S1) - 0.5926(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 30: 0.5791(Model A)    |     0.5852(Model S1) - 0.5652(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 31: 0.5772(Model A)    |     0.5835(Model S1) - 0.5487(Model S2) \n",
      "499\n",
      "499\n",
      "490\n",
      "Query 32: 0.6051(Model A)    |     0.5986(Model S1) - 0.5116(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 33: 0.5903(Model A)    |     0.5907(Model S1) - 0.5619(Model S2) \n",
      "499\n",
      "499\n",
      "480\n",
      "Query 34: 0.5867(Model A)    |     0.6005(Model S1) - 0.5195(Model S2) \n",
      "499\n",
      "499\n",
      "440\n",
      "Query 35: 0.5787(Model A)    |     0.5684(Model S1) - 0.4682(Model S2) \n",
      "499\n",
      "499\n",
      "140\n",
      "Query 36: 0.5809(Model A)    |     0.5789(Model S1) - 0.5689(Model S2) \n",
      "499\n",
      "499\n",
      "490\n",
      "Query 37: 0.5863(Model A)    |     0.5905(Model S1) - 0.4494(Model S2) \n",
      "499\n",
      "499\n",
      "420\n",
      "Query 38: 0.5881(Model A)    |     0.5881(Model S1) - 0.4916(Model S2) \n",
      "499\n",
      "499\n",
      "490\n",
      "Query 39: 0.5871(Model A)    |     0.6030(Model S1) - 0.5351(Model S2) \n",
      "499\n",
      "499\n",
      "460\n",
      "Query 40: 0.5847(Model A)    |     0.5946(Model S1) - 0.5321(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 41: 0.5934(Model A)    |     0.6040(Model S1) - 0.5567(Model S2) \n",
      "499\n",
      "499\n",
      "230\n",
      "Query 42: 0.5931(Model A)    |     0.6060(Model S1) - 0.5762(Model S2) \n",
      "499\n",
      "499\n",
      "330\n",
      "Query 43: 0.6061(Model A)    |     0.6162(Model S1) - 0.5871(Model S2) \n",
      "499\n",
      "499\n",
      "340\n",
      "Query 44: 0.5965(Model A)    |     0.6045(Model S1) - 0.5318(Model S2) \n",
      "499\n",
      "499\n",
      "390\n",
      "Query 45: 0.5853(Model A)    |     0.6000(Model S1) - 0.5702(Model S2) \n",
      "499\n",
      "499\n",
      "250\n",
      "Query 46: 0.5924(Model A)    |     0.6014(Model S1) - 0.5520(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 47: 0.5984(Model A)    |     0.6248(Model S1) - 0.5683(Model S2) \n",
      "499\n",
      "499\n",
      "180\n",
      "Query 48: 0.5999(Model A)    |     0.6025(Model S1) - 0.5625(Model S2) \n",
      "499\n",
      "499\n",
      "440\n",
      "Query 49: 0.5966(Model A)    |     0.6017(Model S1) - 0.5212(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 50: 0.6013(Model A)    |     0.5958(Model S1) - 0.5827(Model S2) \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_98ea7a6f-0773-42d0-9497-27657057c121\", \"res_bald_A1.npy\", 2336)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A1 BALD\n",
    "acquisition_hist, successor1_hist, successor2_hist, scores, pool_idx = active_learning_procedure(\n",
    "                                                                                X_test,\n",
    "                                                                                y_test,\n",
    "                                                                                X_pool,\n",
    "                                                                                y_pool,\n",
    "                                                                                X_initial,\n",
    "                                                                                y_initial,\n",
    "                                                                                n_queries = 50,\n",
    "                                                                                n_instances = 1,\n",
    "                                                                                Model_A = 1, Model_S1 = 2, Model_S2 = 3)\n",
    "with open('res_bald_A1.npy', 'wb') as f:\n",
    "    np.save(f, acquisition_hist)\n",
    "    np.save(f, successor1_hist)\n",
    "    np.save(f, successor2_hist)\n",
    "    np.save(f, scores)\n",
    "\n",
    "from google.colab import files\n",
    "files.download('res_bald_A1.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Iqc95fxHsdap",
    "outputId": "e9bb6018-13ee-4d80-fccd-e69be3fdc3b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "140\n",
      "200\n",
      "499\n",
      "200\n",
      "310\n",
      "Query 1: 0.4852(Model A)    |     0.5020(Model S1) - 0.4912(Model S2) \n",
      "370\n",
      "220\n",
      "180\n",
      "Query 2: 0.4697(Model A)    |     0.4789(Model S1) - 0.4890(Model S2) \n",
      "370\n",
      "170\n",
      "430\n",
      "Query 3: 0.4763(Model A)    |     0.4925(Model S1) - 0.5109(Model S2) \n",
      "330\n",
      "240\n",
      "250\n",
      "Query 4: 0.4412(Model A)    |     0.4515(Model S1) - 0.4570(Model S2) \n",
      "470\n",
      "330\n",
      "230\n",
      "Query 5: 0.4618(Model A)    |     0.4657(Model S1) - 0.4477(Model S2) \n",
      "499\n",
      "220\n",
      "170\n",
      "Query 6: 0.4905(Model A)    |     0.5034(Model S1) - 0.5278(Model S2) \n",
      "499\n",
      "320\n",
      "190\n",
      "Query 7: 0.5015(Model A)    |     0.5070(Model S1) - 0.5266(Model S2) \n",
      "499\n",
      "230\n",
      "230\n",
      "Query 8: 0.5166(Model A)    |     0.5348(Model S1) - 0.5483(Model S2) \n",
      "499\n",
      "499\n",
      "350\n",
      "Query 9: 0.5255(Model A)    |     0.5386(Model S1) - 0.5140(Model S2) \n",
      "499\n",
      "480\n",
      "470\n",
      "Query 10: 0.5325(Model A)    |     0.5323(Model S1) - 0.5307(Model S2) \n",
      "499\n",
      "499\n",
      "190\n",
      "Query 11: 0.5113(Model A)    |     0.5238(Model S1) - 0.5354(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 12: 0.5159(Model A)    |     0.5217(Model S1) - 0.5278(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 13: 0.5618(Model A)    |     0.5644(Model S1) - 0.6127(Model S2) \n",
      "499\n",
      "260\n",
      "360\n",
      "Query 14: 0.5634(Model A)    |     0.5669(Model S1) - 0.5761(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 15: 0.5650(Model A)    |     0.5769(Model S1) - 0.5715(Model S2) \n",
      "499\n",
      "280\n",
      "499\n",
      "Query 16: 0.5585(Model A)    |     0.5693(Model S1) - 0.5790(Model S2) \n",
      "499\n",
      "260\n",
      "140\n",
      "Query 17: 0.5694(Model A)    |     0.5747(Model S1) - 0.5513(Model S2) \n",
      "499\n",
      "450\n",
      "130\n",
      "Query 18: 0.5605(Model A)    |     0.5550(Model S1) - 0.5638(Model S2) \n",
      "499\n",
      "320\n",
      "499\n",
      "Query 19: 0.5880(Model A)    |     0.5995(Model S1) - 0.5917(Model S2) \n",
      "499\n",
      "260\n",
      "499\n",
      "Query 20: 0.5915(Model A)    |     0.5883(Model S1) - 0.6196(Model S2) \n",
      "499\n",
      "290\n",
      "499\n",
      "Query 21: 0.5837(Model A)    |     0.5935(Model S1) - 0.5878(Model S2) \n",
      "499\n",
      "499\n",
      "190\n",
      "Query 22: 0.5854(Model A)    |     0.5900(Model S1) - 0.5891(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 23: 0.5876(Model A)    |     0.5963(Model S1) - 0.6097(Model S2) \n",
      "499\n",
      "499\n",
      "470\n",
      "Query 24: 0.6029(Model A)    |     0.6131(Model S1) - 0.6220(Model S2) \n",
      "499\n",
      "499\n",
      "410\n",
      "Query 25: 0.6027(Model A)    |     0.6140(Model S1) - 0.5652(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 26: 0.6072(Model A)    |     0.6229(Model S1) - 0.6229(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 27: 0.6000(Model A)    |     0.6068(Model S1) - 0.6187(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 28: 0.6000(Model A)    |     0.6167(Model S1) - 0.6140(Model S2) \n",
      "499\n",
      "499\n",
      "480\n",
      "Query 29: 0.5925(Model A)    |     0.6157(Model S1) - 0.5841(Model S2) \n",
      "499\n",
      "220\n",
      "270\n",
      "Query 30: 0.5778(Model A)    |     0.5899(Model S1) - 0.5514(Model S2) \n",
      "499\n",
      "499\n",
      "140\n",
      "Query 31: 0.6070(Model A)    |     0.6168(Model S1) - 0.5736(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 32: 0.6074(Model A)    |     0.6244(Model S1) - 0.6268(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 33: 0.6089(Model A)    |     0.6081(Model S1) - 0.5962(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 34: 0.6410(Model A)    |     0.6482(Model S1) - 0.6379(Model S2) \n",
      "499\n",
      "499\n",
      "330\n",
      "Query 35: 0.6376(Model A)    |     0.6413(Model S1) - 0.6028(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 36: 0.6388(Model A)    |     0.6527(Model S1) - 0.5999(Model S2) \n",
      "499\n",
      "499\n",
      "480\n",
      "Query 37: 0.6278(Model A)    |     0.6397(Model S1) - 0.6325(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 38: 0.6384(Model A)    |     0.6428(Model S1) - 0.6221(Model S2) \n",
      "499\n",
      "499\n",
      "480\n",
      "Query 39: 0.6420(Model A)    |     0.6453(Model S1) - 0.6202(Model S2) \n",
      "499\n",
      "499\n",
      "460\n",
      "Query 40: 0.6371(Model A)    |     0.6593(Model S1) - 0.6815(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 41: 0.6459(Model A)    |     0.6485(Model S1) - 0.6662(Model S2) \n",
      "499\n",
      "499\n",
      "490\n",
      "Query 42: 0.6551(Model A)    |     0.6624(Model S1) - 0.6458(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 43: 0.6463(Model A)    |     0.6589(Model S1) - 0.6558(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 44: 0.6590(Model A)    |     0.6714(Model S1) - 0.6850(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 45: 0.6622(Model A)    |     0.6814(Model S1) - 0.6260(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 46: 0.6785(Model A)    |     0.6901(Model S1) - 0.6999(Model S2) \n",
      "499\n",
      "499\n",
      "290\n",
      "Query 47: 0.6833(Model A)    |     0.6993(Model S1) - 0.6496(Model S2) \n",
      "499\n",
      "499\n",
      "410\n",
      "Query 48: 0.6872(Model A)    |     0.7035(Model S1) - 0.6964(Model S2) \n",
      "499\n",
      "499\n",
      "460\n",
      "Query 49: 0.6949(Model A)    |     0.7132(Model S1) - 0.7022(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 50: 0.6870(Model A)    |     0.7111(Model S1) - 0.6137(Model S2) \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_11881850-bee7-40f9-b2e4-1b14e830fa5f\", \"res_iid_A1.npy\", 2336)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#iid\n",
    "acquisition_hist, successor1_hist, successor2_hist, scores, pool_idx = active_learning_procedure(\n",
    "                                                                                X_test,\n",
    "                                                                                y_test,\n",
    "                                                                                X_pool,\n",
    "                                                                                y_pool,\n",
    "                                                                                X_initial,\n",
    "                                                                                y_initial,\n",
    "                                                                                n_queries = 50,\n",
    "                                                                                n_instances = 1,\n",
    "                                                                                sample_strategy = 'iid',\n",
    "                                                                                Model_A = 1, Model_S1 = 2, Model_S2 = 3)\n",
    "with open('res_iid_A1.npy', 'wb') as f:\n",
    "    np.save(f, acquisition_hist)\n",
    "    np.save(f, successor1_hist)\n",
    "    np.save(f, successor2_hist)\n",
    "    np.save(f, scores)\n",
    "\n",
    "from google.colab import files\n",
    "files.download('res_iid_A1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4rRNshoX8I1S",
    "outputId": "2b937371-80de-4e52-9757-6f5aa6e762e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "280\n",
      "160\n",
      "350\n",
      "380\n",
      "200\n",
      "Query 1: 0.5045(Model A)    |     0.4993(Model S1) - 0.4180(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 2: 0.4743(Model A)    |     0.4733(Model S1) - 0.4707(Model S2) \n",
      "390\n",
      "470\n",
      "499\n",
      "Query 3: 0.4792(Model A)    |     0.4483(Model S1) - 0.4383(Model S2) \n",
      "180\n",
      "499\n",
      "190\n",
      "Query 4: 0.4632(Model A)    |     0.4494(Model S1) - 0.4320(Model S2) \n",
      "180\n",
      "499\n",
      "230\n",
      "Query 5: 0.4313(Model A)    |     0.4163(Model S1) - 0.4444(Model S2) \n",
      "210\n",
      "499\n",
      "499\n",
      "Query 6: 0.4071(Model A)    |     0.3795(Model S1) - 0.4165(Model S2) \n",
      "310\n",
      "480\n",
      "190\n",
      "Query 7: 0.4354(Model A)    |     0.4273(Model S1) - 0.3993(Model S2) \n",
      "190\n",
      "270\n",
      "499\n",
      "Query 8: 0.4427(Model A)    |     0.4201(Model S1) - 0.4479(Model S2) \n",
      "220\n",
      "499\n",
      "190\n",
      "Query 9: 0.4934(Model A)    |     0.4796(Model S1) - 0.4349(Model S2) \n",
      "370\n",
      "499\n",
      "190\n",
      "Query 10: 0.4680(Model A)    |     0.4661(Model S1) - 0.4623(Model S2) \n",
      "400\n",
      "499\n",
      "440\n",
      "Query 11: 0.4877(Model A)    |     0.4904(Model S1) - 0.4633(Model S2) \n",
      "499\n",
      "499\n",
      "190\n",
      "Query 12: 0.4998(Model A)    |     0.4908(Model S1) - 0.4753(Model S2) \n",
      "499\n",
      "410\n",
      "499\n",
      "Query 13: 0.5078(Model A)    |     0.4993(Model S1) - 0.4942(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 14: 0.5170(Model A)    |     0.5000(Model S1) - 0.4874(Model S2) \n",
      "180\n",
      "499\n",
      "210\n",
      "Query 15: 0.4949(Model A)    |     0.4713(Model S1) - 0.4446(Model S2) \n",
      "390\n",
      "499\n",
      "499\n",
      "Query 16: 0.5146(Model A)    |     0.5009(Model S1) - 0.4733(Model S2) \n",
      "210\n",
      "499\n",
      "499\n",
      "Query 17: 0.5100(Model A)    |     0.4982(Model S1) - 0.4794(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 18: 0.5033(Model A)    |     0.5037(Model S1) - 0.4765(Model S2) \n",
      "499\n",
      "499\n",
      "370\n",
      "Query 19: 0.5248(Model A)    |     0.5240(Model S1) - 0.4966(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 20: 0.4970(Model A)    |     0.4812(Model S1) - 0.4713(Model S2) \n",
      "210\n",
      "499\n",
      "499\n",
      "Query 21: 0.4828(Model A)    |     0.5140(Model S1) - 0.4881(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 22: 0.5539(Model A)    |     0.5337(Model S1) - 0.3708(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 23: 0.5229(Model A)    |     0.5186(Model S1) - 0.4898(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 24: 0.5330(Model A)    |     0.5095(Model S1) - 0.5042(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 25: 0.5368(Model A)    |     0.5189(Model S1) - 0.5019(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 26: 0.5589(Model A)    |     0.5331(Model S1) - 0.5233(Model S2) \n",
      "499\n",
      "499\n",
      "390\n",
      "Query 27: 0.5342(Model A)    |     0.5432(Model S1) - 0.4776(Model S2) \n",
      "499\n",
      "499\n",
      "330\n",
      "Query 28: 0.5420(Model A)    |     0.5338(Model S1) - 0.5132(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 29: 0.5506(Model A)    |     0.5387(Model S1) - 0.5373(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 30: 0.5506(Model A)    |     0.5281(Model S1) - 0.5179(Model S2) \n",
      "499\n",
      "230\n",
      "499\n",
      "Query 31: 0.5519(Model A)    |     0.5306(Model S1) - 0.5183(Model S2) \n",
      "499\n",
      "499\n",
      "440\n",
      "Query 32: 0.5568(Model A)    |     0.5458(Model S1) - 0.5227(Model S2) \n",
      "499\n",
      "499\n",
      "390\n",
      "Query 33: 0.5676(Model A)    |     0.5473(Model S1) - 0.5518(Model S2) \n",
      "499\n",
      "499\n",
      "420\n",
      "Query 34: 0.5705(Model A)    |     0.5492(Model S1) - 0.5447(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 35: 0.5582(Model A)    |     0.5472(Model S1) - 0.5481(Model S2) \n",
      "499\n",
      "499\n",
      "260\n",
      "Query 36: 0.5750(Model A)    |     0.5619(Model S1) - 0.5090(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 37: 0.5882(Model A)    |     0.5559(Model S1) - 0.5395(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 38: 0.5870(Model A)    |     0.5530(Model S1) - 0.5627(Model S2) \n",
      "499\n",
      "499\n",
      "430\n",
      "Query 39: 0.5712(Model A)    |     0.5613(Model S1) - 0.4723(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 40: 0.5701(Model A)    |     0.5607(Model S1) - 0.5375(Model S2) \n",
      "499\n",
      "480\n",
      "230\n",
      "Query 41: 0.5858(Model A)    |     0.5667(Model S1) - 0.5807(Model S2) \n",
      "499\n",
      "499\n",
      "350\n",
      "Query 42: 0.5806(Model A)    |     0.5700(Model S1) - 0.5163(Model S2) \n",
      "499\n",
      "499\n",
      "380\n",
      "Query 43: 0.5846(Model A)    |     0.5580(Model S1) - 0.5111(Model S2) \n",
      "499\n",
      "499\n",
      "200\n",
      "Query 44: 0.5770(Model A)    |     0.5667(Model S1) - 0.5636(Model S2) \n",
      "499\n",
      "499\n",
      "370\n",
      "Query 45: 0.5880(Model A)    |     0.5698(Model S1) - 0.5060(Model S2) \n",
      "499\n",
      "499\n",
      "370\n",
      "Query 46: 0.5867(Model A)    |     0.5701(Model S1) - 0.5108(Model S2) \n",
      "499\n",
      "499\n",
      "430\n",
      "Query 47: 0.5787(Model A)    |     0.5682(Model S1) - 0.5227(Model S2) \n",
      "499\n",
      "499\n",
      "450\n",
      "Query 48: 0.5630(Model A)    |     0.5657(Model S1) - 0.5346(Model S2) \n",
      "499\n",
      "499\n",
      "220\n",
      "Query 49: 0.5767(Model A)    |     0.5544(Model S1) - 0.5720(Model S2) \n",
      "499\n",
      "499\n",
      "170\n",
      "Query 50: 0.5727(Model A)    |     0.5410(Model S1) - 0.4804(Model S2) \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_c71b0be1-04aa-4d81-8533-e84544280552\", \"res_bald_A2.npy\", 2336)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A2 BALD\n",
    "acquisition_hist, successor1_hist, successor2_hist, scores, pool_idx = active_learning_procedure(\n",
    "                                                                                X_test,\n",
    "                                                                                y_test,\n",
    "                                                                                X_pool,\n",
    "                                                                                y_pool,\n",
    "                                                                                X_initial,\n",
    "                                                                                y_initial,\n",
    "                                                                                n_queries = 50,\n",
    "                                                                                n_instances = 1,\n",
    "                                                                                Model_A = 2, Model_S1 = 1, Model_S2 = 3)\n",
    "with open('res_bald_A2.npy', 'wb') as f:\n",
    "    np.save(f, acquisition_hist)\n",
    "    np.save(f, successor1_hist)\n",
    "    np.save(f, successor2_hist)\n",
    "    np.save(f, scores)\n",
    "\n",
    "from google.colab import files\n",
    "files.download('res_bald_A2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "el4pBQvofl5i",
    "outputId": "a0290ab9-1e58-4273-ce8e-1b209776ceee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "140\n",
      "220\n",
      "300\n",
      "250\n",
      "499\n",
      "Query 1: 0.5003(Model A)    |     0.5122(Model S1) - 0.5020(Model S2) \n",
      "260\n",
      "340\n",
      "499\n",
      "Query 2: 0.4680(Model A)    |     0.4521(Model S1) - 0.4420(Model S2) \n",
      "230\n",
      "499\n",
      "499\n",
      "Query 3: 0.4078(Model A)    |     0.4647(Model S1) - 0.4573(Model S2) \n",
      "240\n",
      "240\n",
      "499\n",
      "Query 4: 0.4504(Model A)    |     0.4573(Model S1) - 0.4470(Model S2) \n",
      "300\n",
      "250\n",
      "370\n",
      "Query 5: 0.4360(Model A)    |     0.4312(Model S1) - 0.4138(Model S2) \n",
      "499\n",
      "290\n",
      "499\n",
      "Query 6: 0.4365(Model A)    |     0.4413(Model S1) - 0.4252(Model S2) \n",
      "499\n",
      "499\n",
      "400\n",
      "Query 7: 0.4381(Model A)    |     0.4855(Model S1) - 0.4588(Model S2) \n",
      "210\n",
      "220\n",
      "430\n",
      "Query 8: 0.4238(Model A)    |     0.4692(Model S1) - 0.4618(Model S2) \n",
      "270\n",
      "180\n",
      "499\n",
      "Query 9: 0.4750(Model A)    |     0.4806(Model S1) - 0.4746(Model S2) \n",
      "260\n",
      "220\n",
      "450\n",
      "Query 10: 0.5029(Model A)    |     0.4930(Model S1) - 0.4770(Model S2) \n",
      "260\n",
      "210\n",
      "499\n",
      "Query 11: 0.4554(Model A)    |     0.4491(Model S1) - 0.4688(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 12: 0.4731(Model A)    |     0.4873(Model S1) - 0.4754(Model S2) \n",
      "260\n",
      "499\n",
      "499\n",
      "Query 13: 0.5200(Model A)    |     0.5118(Model S1) - 0.4956(Model S2) \n",
      "240\n",
      "499\n",
      "499\n",
      "Query 14: 0.4808(Model A)    |     0.5051(Model S1) - 0.5025(Model S2) \n",
      "499\n",
      "260\n",
      "499\n",
      "Query 15: 0.4984(Model A)    |     0.5124(Model S1) - 0.4934(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 16: 0.4974(Model A)    |     0.5070(Model S1) - 0.5036(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 17: 0.4464(Model A)    |     0.5162(Model S1) - 0.4901(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 18: 0.3829(Model A)    |     0.5085(Model S1) - 0.4896(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 19: 0.4891(Model A)    |     0.5226(Model S1) - 0.5009(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 20: 0.5021(Model A)    |     0.5103(Model S1) - 0.5063(Model S2) \n",
      "499\n",
      "340\n",
      "499\n",
      "Query 21: 0.5105(Model A)    |     0.5027(Model S1) - 0.5030(Model S2) \n",
      "130\n",
      "499\n",
      "499\n",
      "Query 22: 0.5104(Model A)    |     0.5250(Model S1) - 0.5002(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 23: 0.4391(Model A)    |     0.4991(Model S1) - 0.5070(Model S2) \n",
      "280\n",
      "499\n",
      "499\n",
      "Query 24: 0.5120(Model A)    |     0.5157(Model S1) - 0.5232(Model S2) \n",
      "370\n",
      "499\n",
      "499\n",
      "Query 25: 0.5380(Model A)    |     0.5496(Model S1) - 0.5364(Model S2) \n",
      "499\n",
      "350\n",
      "499\n",
      "Query 26: 0.5331(Model A)    |     0.5462(Model S1) - 0.5274(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 27: 0.5458(Model A)    |     0.5453(Model S1) - 0.5279(Model S2) \n",
      "170\n",
      "499\n",
      "499\n",
      "Query 28: 0.5883(Model A)    |     0.5726(Model S1) - 0.5486(Model S2) \n",
      "480\n",
      "499\n",
      "499\n",
      "Query 29: 0.4894(Model A)    |     0.5666(Model S1) - 0.5445(Model S2) \n",
      "410\n",
      "499\n",
      "499\n",
      "Query 30: 0.5497(Model A)    |     0.5491(Model S1) - 0.5534(Model S2) \n",
      "310\n",
      "499\n",
      "499\n",
      "Query 31: 0.5245(Model A)    |     0.5479(Model S1) - 0.5573(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 32: 0.5479(Model A)    |     0.5600(Model S1) - 0.5688(Model S2) \n",
      "460\n",
      "499\n",
      "499\n",
      "Query 33: 0.5138(Model A)    |     0.5819(Model S1) - 0.5861(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 34: 0.5611(Model A)    |     0.5793(Model S1) - 0.5913(Model S2) \n",
      "150\n",
      "499\n",
      "499\n",
      "Query 35: 0.5599(Model A)    |     0.5936(Model S1) - 0.5895(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 36: 0.5519(Model A)    |     0.6045(Model S1) - 0.5923(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 37: 0.6074(Model A)    |     0.6104(Model S1) - 0.6082(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 38: 0.6257(Model A)    |     0.6342(Model S1) - 0.6154(Model S2) \n",
      "410\n",
      "499\n",
      "499\n",
      "Query 39: 0.6020(Model A)    |     0.6385(Model S1) - 0.6315(Model S2) \n",
      "470\n",
      "499\n",
      "499\n",
      "Query 40: 0.6136(Model A)    |     0.6342(Model S1) - 0.6301(Model S2) \n",
      "420\n",
      "499\n",
      "499\n",
      "Query 41: 0.6447(Model A)    |     0.6327(Model S1) - 0.6442(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 42: 0.6376(Model A)    |     0.6496(Model S1) - 0.6234(Model S2) \n",
      "160\n",
      "499\n",
      "499\n",
      "Query 43: 0.5922(Model A)    |     0.6537(Model S1) - 0.6357(Model S2) \n",
      "210\n",
      "499\n",
      "499\n",
      "Query 44: 0.5690(Model A)    |     0.6494(Model S1) - 0.6458(Model S2) \n",
      "499\n",
      "499\n",
      "499\n",
      "Query 45: 0.6311(Model A)    |     0.6421(Model S1) - 0.6557(Model S2) \n",
      "410\n",
      "499\n",
      "499\n",
      "Query 46: 0.5905(Model A)    |     0.6581(Model S1) - 0.6538(Model S2) \n",
      "480\n",
      "499\n",
      "499\n",
      "Query 47: 0.6413(Model A)    |     0.6670(Model S1) - 0.6631(Model S2) \n",
      "370\n",
      "499\n",
      "499\n",
      "Query 48: 0.6252(Model A)    |     0.6542(Model S1) - 0.6603(Model S2) \n",
      "330\n",
      "499\n",
      "499\n",
      "Query 49: 0.6391(Model A)    |     0.6556(Model S1) - 0.6606(Model S2) \n",
      "330\n",
      "499\n",
      "499\n",
      "Query 50: 0.5729(Model A)    |     0.6720(Model S1) - 0.6657(Model S2) \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_26a030ce-9fe9-46f0-91ee-f9e023d3e8c6\", \"res_bald_A3.npy\", 2336)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A3 BALD\n",
    "acquisition_hist, successor1_hist, successor2_hist, scores, pool_idx = active_learning_procedure(\n",
    "                                                                                X_test,\n",
    "                                                                                y_test,\n",
    "                                                                                X_pool,\n",
    "                                                                                y_pool,\n",
    "                                                                                X_initial,\n",
    "                                                                                y_initial,\n",
    "                                                                                n_queries = 50,\n",
    "                                                                                n_instances = 1,\n",
    "                                                                                Model_A = 3, Model_S1 = 2, Model_S2 = 1)\n",
    "with open('res_bald_A3.npy', 'wb') as f:\n",
    "    np.save(f, acquisition_hist)\n",
    "    np.save(f, successor1_hist)\n",
    "    np.save(f, successor2_hist)\n",
    "    np.save(f, scores)\n",
    "\n",
    "from google.colab import files\n",
    "files.download('res_bald_A3.npy')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of VI_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03fa8fa1e39e4399a6b8b51574bb8111": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ab2de4d902d4c56a61692f0a690bdd7",
      "max": 4542,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_08ec92006dea47eba9b4ed2f0db1276a",
      "value": 4542
     }
    },
    "064ed0f2746542eab159676f143a8fda": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_42b57a85269d4097bea4732dd89df437",
       "IPY_MODEL_5575a9af1ddb432d81995c2170d5d59f"
      ],
      "layout": "IPY_MODEL_99c0825de8e746db8dc4e5af38bd16fa"
     }
    },
    "08ec92006dea47eba9b4ed2f0db1276a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0ab2de4d902d4c56a61692f0a690bdd7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16fc57603dce4b8aa6e1de8fe8402d26": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20feae755dad40728314b73c5597190f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "210a6f76fd77403ebd788eb544fe1671": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24d11fd8db6e46958b0e4cb53126f9f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2e6d92897705487d917b7b2115a75216": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31a5d349ec3c498d83b23c5b3736b168": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d68c35ed769410cbbcc0606c39c0b54": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42b57a85269d4097bea4732dd89df437": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3dc2d9352384c11823eee607c854cce",
      "max": 1648877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5dae32f55bc64e348d5c01204c4a84c9",
      "value": 1648877
     }
    },
    "4f9cb9be49ab48e7b36a680e2830a130": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "511af83aeba1488897d2cff3b477bdc8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54ddd446c8c547ae9b70da4f20350259": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c960465d06cd4a018834f964fe098373",
       "IPY_MODEL_d7eede79b5e04dfeaba41490f9dc378f"
      ],
      "layout": "IPY_MODEL_bc9832a8f3944333b0e7a500bf030084"
     }
    },
    "550efb7acd39429c8c48c7a5c1976a78": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_839891b6adfa46f5aae58ee71d0fd15c",
      "placeholder": "​",
      "style": "IPY_MODEL_6a5a761c9dc04a1c9d7751e21a81f5d7",
      "value": " 29696/? [00:06&lt;00:00, 4550.83it/s]"
     }
    },
    "5575a9af1ddb432d81995c2170d5d59f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b275a2aa837349a7b1d912e69286e917",
      "placeholder": "​",
      "style": "IPY_MODEL_210a6f76fd77403ebd788eb544fe1671",
      "value": " 1649664/? [00:03&lt;00:00, 468344.40it/s]"
     }
    },
    "5dae32f55bc64e348d5c01204c4a84c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6a5a761c9dc04a1c9d7751e21a81f5d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7218851bd204444aa887e0e094b8506f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_03fa8fa1e39e4399a6b8b51574bb8111",
       "IPY_MODEL_c7762d684bb143b895a527f0872cbf79"
      ],
      "layout": "IPY_MODEL_16fc57603dce4b8aa6e1de8fe8402d26"
     }
    },
    "7a84aecefa8744359710be1e6bf2107a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bbd84446f4174fe49e628369b4aee077",
       "IPY_MODEL_550efb7acd39429c8c48c7a5c1976a78"
      ],
      "layout": "IPY_MODEL_2e6d92897705487d917b7b2115a75216"
     }
    },
    "839891b6adfa46f5aae58ee71d0fd15c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99c0825de8e746db8dc4e5af38bd16fa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3dc2d9352384c11823eee607c854cce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b275a2aa837349a7b1d912e69286e917": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbd84446f4174fe49e628369b4aee077": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca122b207f2d4c90b9e9119af9a0fc0d",
      "max": 28881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_24d11fd8db6e46958b0e4cb53126f9f7",
      "value": 28881
     }
    },
    "bc9832a8f3944333b0e7a500bf030084": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7762d684bb143b895a527f0872cbf79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d68c35ed769410cbbcc0606c39c0b54",
      "placeholder": "​",
      "style": "IPY_MODEL_31a5d349ec3c498d83b23c5b3736b168",
      "value": " 5120/? [00:00&lt;00:00, 23107.99it/s]"
     }
    },
    "c960465d06cd4a018834f964fe098373": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_511af83aeba1488897d2cff3b477bdc8",
      "max": 9912422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dc5c8217441b439980dc5f042ac50c3e",
      "value": 9912422
     }
    },
    "ca122b207f2d4c90b9e9119af9a0fc0d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7eede79b5e04dfeaba41490f9dc378f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f9cb9be49ab48e7b36a680e2830a130",
      "placeholder": "​",
      "style": "IPY_MODEL_20feae755dad40728314b73c5597190f",
      "value": " 9913344/? [00:11&lt;00:00, 894432.61it/s]"
     }
    },
    "dc5c8217441b439980dc5f042ac50c3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
